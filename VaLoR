#!/usr/bin/env python

#!python
#For debug use only
#command='Pacbio.Validator.py svelter --sv-input /scratch/remills_flux/xuefzhao/NA12878.NGS/SVelter_NA12878_new_SVelter4.svelter --output-path /scratch/remills_flux/xuefzhao/NA12878.NGS/PacbioVali/ --pacbio-input /scratch/remills_flux/xuefzhao/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /scratch/remills_flux/xuefzhao/NA12878.NGS/reference/genome.fa'
#command='Pacbio.Validator.py svelter --sv-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/NA12878_S1.chr22.sorted.svelter --output-path /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/PacValTest/ --pacbio-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /mnt/EXT/Mills-scratch2/reference/hg19_platinum/genome.fa'
#command='Pacbio.Validator.py vcf --sv-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/NA12878_S1.chr22.sorted.vcf --output-path /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/PacValTest/ --pacbio-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /mnt/EXT/Mills-scratch2/reference/hg19_platinum/genome.fa'
#command='Pacbio.Validator.py vcf --sv-input /mnt/EXT/Mills-scratch2/Xuefang/Simulate.FussyJunc/Simulate.comp/comp.het/SVelter/test.for.debug.vcf --output-path /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/PacValTest/ --pacbio-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /mnt/EXT/Mills-scratch2/reference/hg19_platinum/genome.fa'
#Tet deletions:
#command='Pacbio.Validator.py vcf --sv-input /mnt/EXT/Mills-scratch2/Xuefang/Pacbio.Validator/vcf_files/NA12878_Delly_DEL.vcf --output-path /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/PacValTest/ --pacbio-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /mnt/EXT/Mills-scratch2/reference/hg19_platinum/genome.fa'
#Tet inversions:
#command='Pacbio.Validator.py vcf --sv-input /mnt/EXT/Mills-scratch2/Xuefang/Pacbio.Validator/vcf_files/NA12878_Delly_INV.vcf --output-path /mnt/EXT/Mills-scratch2/Xuefang/NA12878.NGS/SVelter_rec2/PacValTest/ --pacbio-input /mnt/EXT/Mills-scratch2/Xuefang/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /mnt/EXT/Mills-scratch2/reference/hg19_platinum/genome.fa'
#Tet SVelter:
#command='Pacbio.Validator.py bed --sv-input /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.version4/NA19240.sorted.DEL.bed --output-path /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.version4/NA19240.sorted.DEL.SV.Validate/ --pacbio-input /scratch/remills_flux/xuefzhao/SV_discovery_index/smrt.download/alignment/NA19240.XXX.bam --reference /scratch/remills_flux/xuefzhao/reference/GRCh38.1KGP/GRCh38_full_analysis_set_plus_decoy_hla.fa --sv-type DEL'
#command='Pacbio.Validator.py vcf --sv-input /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.version4/vcf_files/NA19240.sorted.vcf --output-path /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.version4/NA19240.vcf.PacbioValidation --pacbio-input /scratch/remills_flux/xuefzhao/SV_discovery_index/smrt.download/alignment/NA19240.XXX.bam --reference /scratch/remills_flux/xuefzhao/reference/GRCh38.1KGP/GRCh38_full_analysis_set_plus_decoy_hla.fa'
#command='Pacbio.Validator.py vcf --sv-input /scratch/remills_flux/xuefzhao/PacbioValidation/1000G_SV_Calls/NA12878_SV_chr_vcf/ALL.chr1.phase3_shapeit2_mvncall_integrated_v5.20130502.genotypes.NA12878.SV.chr.vcf --output-path /scratch/remills_flux/xuefzhao/PacbioValidation/1000G_SV_Calls/NA12878.vcf.PacbioValidation --pacbio-input /scratch/remills_flux/xuefzhao/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /scratch/remills_flux/xuefzhao/reference/hg19/hg19.fa'
#command='Pacbio.Validator.py vcf --sv-input /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.CommonBPs/NA19240.Common.BPs.vcf --output-path /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.CommonBPs/NA19240.vcf.PacbioValidation --pacbio-input /scratch/remills_flux/xuefzhao/SV_discovery_index/smrt.download/alignment/NA19240.XXX.bam --reference /scratch/remills_flux/xuefzhao/reference/GRCh38.1KGP/GRCh38_full_analysis_set_plus_decoy_hla.fa'
#command='Pacbio.Validator.py svelter --sv-input /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.CommonBPs/NA19240.Common.BPs.svelter --output-path /scratch/remills_flux/xuefzhao/SV_discovery_index/download/SVelter.CommonBPs/NA19240.svelter.PacbioValidation --pacbio-input /scratch/remills_flux/xuefzhao/SV_discovery_index/smrt.download/alignment/NA19240.XXX.bam --reference /scratch/remills_flux/xuefzhao/reference/GRCh38.1KGP/GRCh38_full_analysis_set_plus_decoy_hla.fa'
#command='Pacbio.Validator.py svelter --sv-input /scratch/remills_flux/xuefzhao/PacbioValidation/CHM1/CHM1.test --output-path /scratch/remills_flux/xuefzhao/PacbioValidation/CHM1 --pacbio-input /scratch/remills_flux/xuefzhao/CHM1/Pacbio/alignment/SAMN02744161.pacbio.sorted.bam --reference /nfs/remills-scratch2/reference/GRCh37/human_g1k_v37.fasta'
#command='Pacbio.Validator.py bed --sv-input /scratch/remills_flux/xuefzhao/PacbioValidation/NA12878/NIST_DEL/Personalis_1000_Genomes_deduplicated_deletions.bed --output-path /scratch/remills_flux/xuefzhao/PacbioValidation/NA12878/NIST_DEL_Vali --pacbio-input /scratch/remills_flux/xuefzhao/NA12878.Pacbio/alignment/sorted_final_merged.bam --reference /scratch/remills_flux/xuefzhao/reference/hg19/hg19.fa --sv-type del'

#sys.argv=command.split()
import os
import re
import sys
import matplotlib
import time
matplotlib.use('Agg') 
def print_read_me():
	print 'Pacbio.Validator.py V1.0 12-21-2015'
	print 'Contact: Xuefang Zhao (xuefzhao@umich.edu)'
	print ''
	print 'Usage: acbio.Validator.py [Options] [Parameters]'
	print 'Options: '
	print '	svelter'
	print '	vcf'
	print ' bed'
	print 'Parameters:'
	print '	--sv-input:'
	print ' --output-path:'
	print '	--pacbio-input:'
	print '	--reference:'
	print 'Optional Parameters:'
	print '	--window-size'
	print '	--sv-type'

if len(sys.argv)<2: 
	print_read_me()
else:
	import getopt
	import numpy
	import scipy
	import random
	import math
	import numpy as np
	from numpy import vstack,array
	from numpy.random import rand
	from scipy.cluster.vq import vq, kmeans, whiten
	from scipy import stats
	from scipy.stats import linregress
	from sklearn import cluster
	from scipy.spatial import distance
	import sklearn.datasets
	from sklearn.preprocessing import StandardScaler
	import matplotlib.pyplot as plt
	import plotting
	function_name=sys.argv[1]
	invert_base = { 'A' : 'T', 'T' : 'A', 'C' : 'G', 'G' : 'C','N' : 'N','a' : 't', 't' : 'a', 'c' : 'g', 'g' : 'c','n' : 'n'}
	lenght_cff=100
	dots_num_cff=20
	clu_dis_cff=5
	point_dis_cff=20
	simple_dis_cff=100#min resolution:50bp
	def alt_sv_to_list(alt_sv):
		out=[[],[]]
		for x in alt_sv.split('/')[0]:
				if not x=='^':
						out[0].append(x)
				else:
						out[0][-1]+=x
		for x in alt_sv.split('/')[1]:
				if not x=='^':
						out[1].append(x)
				else:
						out[1][-1]+=x
		return out
	def bam_in_decide(bam_in,bps):
		if os.path.isfile(bam_in):
			return bam_in
		else:
			temp_bam_in=[]
			bam_in_path='/'.join(bam_in.split('/')[:-1])+'/'
			bam_in_keys=bam_in.split('/')[-1].split('XXX')
			for k1 in os.listdir(bam_in_path):
				if k1.split('.')[-1]==bam_in.split('.')[-1]:
					flag=0
					for y in bam_in_keys:
						if not y in k1:
							flag+=1
					if flag==0:
						temp_bam_in.append(bam_in_path+k1)
			bam_out=''
			for x in temp_bam_in:
				if bps[0]+'.' in x: # if bam files were separated by chromosome, we requre chromo+'.' to be in the name , eg; "namepart.chr1.namepart.bam"
					bam_out=x
			if not bam_out=='':
				return bam_out
			else:
				print 'error: pacbio file not found!'
				return bam_out
	def bl_len_hash_calculate(bps,ref_sv):
		bl_len_hash={}
		for x in ref_sv.split('/')[0]:
			bl_len_hash[x]=int(bps[ord(x)-97+2])-int(bps[ord(x)-97+1])
		return bl_len_hash
	def bps_check(bps):
		flag=0
		for x in bps[1:]:
			if x in chromosomes:
				return 1
		for x in range(len(bps)-2):
			if int(bps[x+2])-int(bps[x+1])>10**6:
				flag+=1
		return flag
	def bp_let_to_hash(info,flank_length):
		k1=info[0]
		k3=info[2:]
		out_hash={}
		let_info=['left']+[i for i in k1.split('/')[0]]+['right']
		k3_info=[int(i) for i in k3[1:]]
		k3_info_new=[k3_info[0]-flank_length]+k3_info+[k3_info[-1]+flank_length]
		rec=-1
		for x in let_info:
			rec+=1
			out_hash[x]=[k3_info_new[rec]+1,k3_info_new[rec+1]]
		out_hash_keys=out_hash.keys()
		for x in out_hash_keys:
			out_hash[x+'^']=out_hash[x]
		return out_hash
	def Command_parametre_readin():
		opts,args=getopt.getopt(sys.argv[2:],'i:',['sv-input=','reference=','pacbio-input=','output-path=','sv-type='])
		global dict_opts
		dict_opts=dict(opts)
		global out_path
		out_path=path_modify(dict_opts['--output-path'])
		path_mkdir(out_path)
		global out_file_Cannot_Validate
		out_file_Cannot_Validate=out_path+'Unable.to.validate.rec'
		file_initiate(out_file_Cannot_Validate)
		global sample_name
		sample_name='.'.join(dict_opts['--sv-input'].split('/')[-1].split('.')[:-1])
		global window_size
		if '--window-size' in dict_opts.keys():
			window_size=int(dict_opts['--window-size'])
		else:
			window_size=10
		global start
		start=0
		global delta
		delta=50
		global bam_in
		bam_in=dict_opts['--pacbio-input']
		global ref
		ref=dict_opts['--reference']
		global chromosomes
		chromosomes=chromos_readin(ref)
		global flank_length
		flank_length=500
		global region_QC_Cff
		region_QC_Cff=0.4#QC score for repetitive regions; score=dots on diagnal / all dots when plotting ref vs. ref
		global min_length
		min_length=50
		global min_read_compare
		min_read_compare=20
		global case_number
		case_number=-1
		qc_ref_file_initiate()
	def plot_dotdata_qual_check(QC_plot_name,dotdata_qual_check):				
		with PdfPages(QC_plot_name) as pdf:
			plt.figure(figsize=(3, 3))
			plt.plot([i[0] for i in dotdata_qual_check], [i[0] for i in dotdata_qual_check], 'ro')
			pdf.savefig()  # saves the current figure into a pdf page
			plt.close()
	def qc_ref_file_initiate():
		global qc_file_name
		qc_file_name=out_path+'reference_QC.rec'
		if not os.path.isfile(qc_file_name):
			fo=open(qc_file_name,'w')
			print >>fo, ' '.join(['sample_name','chromosome','bp1','bp2','diagnal_per','rep_per'])
			fo.close()
	def qc_ref_file_write(bps,region_QC,affix,seq2):
		if affix=='':
			fo=open(qc_file_name,'a')
			print >>fo, ' '.join([str(i) for i in [sample_name]+bps+[region_QC[0],max(region_QC[1])/float(len(seq2))]])
			fo.close()
		else:
			fo=open(qc_file_name,'a')
			print >>fo, ' '.join([str(i) for i in [sample_name]+bps+[region_QC[0],max(region_QC[1])/float(len(seq2))]+[affix]])
			fo.close()
	def qc_ref_region_check(out_path,sample_name,info):
		k1=info[0]
		k2=info[1]
		k3=info[2:]
		case_name='_'.join([str(i) for i in k3+[k1.replace('/','-'),k2.replace('/','-')]])
		txt_file=out_path+case_name+'.txt'
		#fo=open(txt_file,'w')
		#print >>fo, ' '.join([str(i) for i in [k1,k2]+k3])
		#fo.close()
		ref_sv=info[0]
		alt_sv=info[1]
		chrom=info[2]
		bps=info[2:]
		#delta=delta_calculate(bps)
		if bps[2]-bps[1]<5000:
			flank_length=flank_length_calculate(bps)
			seqs=Pacbio_prodce_ref_alt_short(ref,flank_length,info)
			seq2=seqs[0]
			dotdata_qual_check=dotdata(window_size,seq2[flank_length:-flank_length],seq2[flank_length:-flank_length])
			region_QC=qual_check_repetitive_region(dotdata_qual_check)
			QC_plot_name=out_path+sample_name+'.'+'.'.join([str(i) for i in bps])+'.png'
			p = makeDotplot(QC_plot_name, dotdata_qual_check, len(seq2), len(seq2))
			qc_ref_file_write(bps, region_QC,'ab',seq2)		
		else:
			flank_length=500
			info_a=info[:3]+[info[3]-500,info[3]+500]
			info_b=info[:3]+[info[4]-500,info[4]+500]
			#left bp flank
			seqs=Pacbio_prodce_ref_alt_short(ref,flank_length,info_a)
			seq2=seqs[0]
			dotdata_qual_check=dotdata(window_size,seq2,seq2)
			region_QC=qual_check_repetitive_region(dotdata_qual_check)
			QC_plot_name=out_path+sample_name+'.'+'.'.join([str(i) for i in bps])+'.a.png'
			p = makeDotplot(QC_plot_name, dotdata_qual_check, len(seq2), len(seq2))
			qc_ref_file_write(bps, region_QC,'a',seq2)		
			#right bp flank
			seqs=Pacbio_prodce_ref_alt_short(ref,flank_length,info_b)
			seq2=seqs[0]
			dotdata_qual_check=dotdata(window_size,seq2,seq2)
			region_QC=qual_check_repetitive_region(dotdata_qual_check)
			QC_plot_name=out_path+sample_name+'.'+'.'.join([str(i) for i in bps])+'.b.png'
			p = makeDotplot(QC_plot_name, dotdata_qual_check, len(seq2), len(seq2))
			qc_ref_file_write(bps, region_QC,'b',seq2)		
	def calcu_eu_dis_simple_short(out_path,sample_name,info,SV_index):
		#eg of info:['a/a', 'a^/a^', '8', '1412203', '1412359']
		#for debug only:
		#k3= case_hash[k1][k2][1]
		#info=[k1,k2]+k3
		k1=info[0]
		k2=info[1]
		k3=info[2:]
		case_name='_'.join([str(i) for i in k3+[k1.replace('/','-'),k2.replace('/','-')]])
		txt_file=out_path+case_name+'.txt'
		#fo=open(txt_file,'w')
		#print >>fo, ' '.join([str(i) for i in [k1,k2]+k3])
		#fo.close()
		ref_sv=info[0]
		alt_sv=info[1]
		chrom=info[2]
		bps=info[2:]
		#delta=delta_calculate(bps)
		flank_length=flank_length_calculate(bps)
		if bps_check(bps)==0:
			bl_len_hash=bl_len_hash_calculate(bps,ref_sv)
			end_point=end_point_calculate(alt_sv,bl_len_hash)
			all_reads=chop_pacbio_read_simple_short(info,flank_length)
			if not all_reads[0]==[]:
				all_reads_new=read_hash_minimize(all_reads)
				read_hash=all_reads_new[0]
				miss_hash=all_reads_new[1]
				name_hash=name_hash_modify(all_reads_new[2])
				rsquare_ref=[]
				rsquare_alt1=[]
				rsquare_alt2=[]
				rec_len=0
				rec_len_rev=-1
				rec_start=0
				rec_name='0'
				if not read_hash==[]:
					seqs=Pacbio_prodce_ref_alt_short(ref,flank_length,info)
					seq2=seqs[0]
					dotdata_qual_check=dotdata(window_size,seq2[flank_length:-flank_length],seq2[flank_length:-flank_length])
					region_QC=qual_check_repetitive_region(dotdata_qual_check)
					QC_plot_name=out_path+sample_name+'.'+'.'.join([str(i) for i in bps])+'.png'
					#p = makeDotplot(QC_plot_name, dotdata_qual_check, len(seq2), len(seq2))
					qc_ref_file_write(bps, region_QC,'ab',seq2)
					if region_QC[0]>region_QC_Cff or max(region_QC[1])/float(len(seq2))<0.3:
						seq3=seqs[1]
						seq4=seqs[2]
						seq_length_limit=min([len(seq2),len(seq3),len(seq4)])
						miss_rec=-1
						dotdata_for_record=[[],[],[]]
						seq1=''
						QC_record=0
						for x in read_hash:
							miss_rec+=1
							y=x
							y2=miss_hash[miss_rec]
							y3=name_hash[miss_rec]
							dotdata_ref=dotdata(window_size,y,seq2)
							#read_QC=qual_check_repetitive_region(dotdata_ref)
							if float(len(dotdata_ref))/float(len(seq2)-2*flank_length)>0.1 and float(len(dotdata_ref))/float(len(seq2)-2*flank_length)<10:
								QC_record+=1
								dotdata_alt1=dotdata(window_size,y,seq3)
								dotdata_alt2=dotdata(window_size,y,seq4)							
								eu_dis_calcu_check_dup(dotdata_ref,dotdata_alt1,dotdata_alt2,rsquare_ref,rsquare_alt1,rsquare_alt2,y2,delta,info)
								if not len(rsquare_ref)==len(rsquare_alt1)==len(rsquare_alt2):
									min_len=min([len(rsquare_ref),len(rsquare_alt1),len(rsquare_alt2)])
									rsquare_ref=rsquare_ref[:min_len]
									rsquare_alt1=rsquare_alt1[:min_len]
									rsquare_alt2=rsquare_alt2[:min_len]
								if not rsquare_alt1==[]:
									if rsquare_ref[-1]==0:
										rsquare_ref[-1]+=1
										rsquare_alt1[-1]+=1
										rsquare_alt2[-1]+=1
									if float(min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])<rec_len:
										if y2 < seq_length_limit:
											rec_len=float(min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])
											rec_start=y2
											rec_name=y3
											seq1=y
											dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
									if float(max([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])>rec_len_rev:
										if y2 < seq_length_limit:
											rec_len_rev=float(max([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])
											rec_start_rev=y2
											rec_name_rev=y3
											seq1_rev=y
						if QC_record>0:
							if rec_len==0:
								dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
								rec_name=y3
								rec_start=y2
								seq1=y
							if rec_len_rev==-1:
								rec_name_rev=y3
								rec_start_rev=y2
								seq1_rev=y
							if len(dotdata_for_record[0])>0:
								dotplot_subfigure_simple_short(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+'.alt.'+rec_name+'.png')
								dotplot_subfigure_simple_short(window_size,seq1_rev,seq2[rec_start_rev:],seq3[rec_start_rev:],seq4[rec_start_rev:],out_path+sample_name+'.'+case_name+'.ref.'+rec_name_rev+'.png')
							write_pacval_individual_stat_simple_short(txt_file,rsquare_ref,rsquare_alt1,rsquare_alt2,SV_index)
						else:
							fo=open(out_file_Cannot_Validate,'a')
							print >>fo, ' '.join([str(i) for i in info])
							fo.close()
					else:
						fo=open(out_file_Cannot_Validate,'a')
						print >>fo, ' '.join([str(i) for i in info])
						fo.close()
			else:
				write_null_individual_stat(txt_file)
				remove_files_short(txt_file)
	def calcu_eu_dis_simple_ins_short(out_path,sample_name,info,SV_index):
		k1=info[0]
		k2=info[1]
		k3=info[2:]
		k3[2]+=k3[1]
		case_name='_'.join([str(i) for i in k3+[k1.replace('/','-'),k2.replace('/','-')]])
		txt_file=out_path+case_name+'.txt'
		ref_sv=info[0]
		alt_sv=info[1]
		chrom=info[2]
		bps=k3
		flank_length=flank_length_calculate(bps)
		if bps_check(bps)==0:
			#bl_len_hash=bl_len_hash_calculate(bps,ref_sv)
			#end_point=end_point_calculate(alt_sv,bl_len_hash)
			all_reads=chop_pacbio_read_left(info[2:4],flank_length)
			if not all_reads[0]==[]:
				all_reads_new=read_hash_minimize(all_reads)
				read_hash=all_reads_new[0]
				miss_hash=all_reads_new[1]
				name_hash=name_hash_modify(all_reads_new[2])
				rsquare_ref=[]
				rsquare_alt1=[]
				rsquare_alt2=[]
				dotdata_ref=[]
				dotdata_alt1=[]
				dotdata_alt2=[]
				rec_len=0
				rec_len_rev=1
				rec_start=0
				rec_name='0'
				if not read_hash==[]:
					seqs=Pacbio_prodce_ref_alt_ins_short(ref,flank_length,[k1,k2]+k3)
					seq2=seqs[0]
					dotdata_qual_check=dotdata(window_size,seq2,seq2)
					region_QC=qual_check_repetitive_region(dotdata_qual_check)
					QC_plot_name=out_path+sample_name+'.'+'.'.join([str(i) for i in bps])+'.png'
					#p = makeDotplot(QC_plot_name, dotdata_qual_check, len(seq2), len(seq2))
					qc_ref_file_write(bps, region_QC,'ab',seq2)
					if region_QC[0]>region_QC_Cff or max(region_QC[1])/float(len(seq2))<0.3:
						seq3=seqs[1]
						seq4=seqs[2]
						seq_length_limit=min([len(seq2),len(seq3),len(seq4)])
						miss_rec=-1
						dotdata_for_record=[[],[],[]]
						seq1=''
						for x in read_hash:
							miss_rec+=1
							y=x
							y2=miss_hash[miss_rec]
							y3=name_hash[miss_rec]
							dotdata_ref=dotdata(window_size,y,seq2[y2:])
							if float(len(dotdata_ref))/float(len(dotdata_qual_check))>0.1 and float(len(dotdata_ref))/float(len(dotdata_qual_check))<10:
								dotdata_alt1=dotdata(window_size,y,seq3[y2:])
								dotdata_alt2=dotdata(window_size,y,seq4[y2:])	
								rsquare_ref.append(eu_dis_calcu_simple_long(dotdata_ref))	
								rsquare_alt1.append(eu_dis_calcu_simple_long(dotdata_alt1))
								rsquare_alt2.append(eu_dis_calcu_simple_long(dotdata_alt2))
								#eu_dis_calcu_check_dup(dotdata_ref,dotdata_alt1,dotdata_alt2,rsquare_ref,rsquare_alt1,rsquare_alt2,y2,delta,info)
								if not len(rsquare_ref)==len(rsquare_alt1)==len(rsquare_alt2):
									min_len=min([len(rsquare_ref),len(rsquare_alt1),len(rsquare_alt2)])
									rsquare_ref=rsquare_ref[:min_len]
									rsquare_alt1=rsquare_alt1[:min_len]
									rsquare_alt2=rsquare_alt2[:min_len]
								if not rsquare_alt1==[]:
									if rsquare_ref[-1]==0:
										rsquare_ref[-1]+=1
										rsquare_alt1[-1]+=1
										rsquare_alt2[-1]+=1
									if float(max([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])>rec_len:
										if y2<seq_length_limit:
											rec_len=float(max([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])
											rec_start=y2
											rec_name=y3
											seq1=y
											dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
									if float(min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])<rec_len_rev:
										if y2<seq_length_limit:
											rec_len_rev=float(min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1])/float(rsquare_ref[-1])
											rec_start_rev=y2
											rec_name_rev=y3
											seq1_rev=y
						if rec_len==0:
							dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
							rec_name=y3
							rec_start=y2
							seq1=y
						if rec_len_rev==1:
							rec_start_rev=y2
							rec_name_rev=y3
							seq1_rev=y
						if len(dotdata_for_record[0])>0:
							dotplot_subfigure_simple_short(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+'.alt.'+rec_name+'.png')
							dotplot_subfigure_simple_short(window_size,seq1_rev,seq2[rec_start_rev:],seq3[rec_start_rev:],seq4[rec_start_rev:],out_path+sample_name+'.'+case_name+'.ref.'+rec_name_rev+'.png')
						write_pacval_individual_stat_simple_short(txt_file,rsquare_ref,rsquare_alt1,rsquare_alt2,SV_index)
					else:
						fo=open(out_file_Cannot_Validate,'a')
						print >>fo, ' '.join([str(i) for i in info])
						fo.close()
			else:
				write_null_individual_stat(txt_file)
				remove_files_short(txt_file)
	def calcu_eu_dis_simple_long(out_path,sample_name,info,SV_index):
		k1=info[0]
		k2=info[1]
		k3=info[2:]
		chrom=info[2]
		case_name='_'.join([str(i) for i in k3])
		txt_file=out_path+case_name+'.txt'
		flank_length=500
		bp_let_hash=bp_let_to_hash(info,flank_length)
		letters=let_to_letters(k2)
		for x_let in letters:
			for y in range(len(x_let)-1):
				junction=x_let[y]+x_let[y+1]
				if not junc_check(junction,k1)==1: #Normal junctions
					bps_temp=decide_bp_temp(chrom,junction,bp_let_hash)
					all_reads_left=chop_pacbio_read_left(bps_temp,flank_length)
					#all_reads_right=chop_pacbio_read_right(bps_temp,flank_length)
					all_reads_right=[[],[],[]]#for now, need a better idea how to deal with this
					read_hash_left=all_reads_left[0]
					miss_hash_left=all_reads_left[1]
					name_hash_left=name_hash_modify(all_reads_left[2])
					read_hash_right=all_reads_right[0]
					miss_hash_right=all_reads_right[1]
					name_hash_right=name_hash_modify(all_reads_right[2])
					seqs=Pacbio_prodce_ref_alt_junc(ref,flank_length,info,junction,bp_let_hash)
					seq2=seqs[0]
					dotdata_qual_check=dotdata(window_size,seq2,seq2)
					region_QC_a=qual_check_repetitive_region(dotdata_qual_check)
					seq3=seqs[1]
					dotdata_qual_check=dotdata(window_size,seq3,seq3)
					region_QC_b=qual_check_repetitive_region(dotdata_qual_check)
					if region_QC_a[0]>region_QC_Cff or sum(region_QC_a[1])/float(len(seq2))<0.3:
						if region_QC_b[0]>region_QC_Cff or sum(region_QC_b[1])/float(len(seq3))<0.3:
							seq4=seqs[2]
							rsquare_ref1=[]
							rsquare_ref2=[]
							rsquare_alt=[]
							seq1=''
							seq_length_limit=min([len(seq2),len(seq3),len(seq4)])
							if not read_hash_left==[]:
								miss_rec=-1
								rec_len=0
								rec_len_rev=1
								new_all_reads_left=read_hash_minimize(all_reads_left)
								read_hash_left=new_all_reads_left[0]
								miss_hash_left=new_all_reads_left[1]
								name_hash_left=name_hash_modify(new_all_reads_left[2])
								for x in read_hash_left:
									miss_rec+=1
									y=x
									y2=miss_hash_left[miss_rec]
									y3=name_hash_left[miss_rec]
									dotdata_ref1=dotdata(window_size,y,seq2[y2:])
									dotdata_ref2=dotdata(window_size,y,seq3[y2:])
									dotdata_alt=dotdata(window_size,y,seq4[y2:])							
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref1)
									#if not temp_rsquare==0:
									rsquare_ref1.append(temp_rsquare)
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref2)
									#if not temp_rsquare==0:
									rsquare_ref2.append(temp_rsquare)
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_alt)
									#if not temp_rsquare==0:
									rsquare_alt.append(temp_rsquare)
									if not rsquare_ref2==[]:
										if float(max([rsquare_ref1[-1],rsquare_ref2[-1]]))==0:
											rsquare_alt[-1]+=1
											rsquare_ref1[-1]+=1
											rsquare_ref2[-1]+=1
										if float(rsquare_alt[-1]-max([rsquare_ref1[-1],rsquare_ref2[-1]]))/float(max([rsquare_ref1[-1],rsquare_ref2[-1]]))>rec_len:
											if miss_hash_left[miss_rec]<seq_length_limit:
												rec_len=float(rsquare_alt[-1]-max([rsquare_ref1[-1],rsquare_ref2[-1]]))/float(max([rsquare_ref1[-1],rsquare_ref2[-1]]))
												rec_name=name_hash_left[miss_rec]
												rec_start=miss_hash_left[miss_rec]
												seq1=y
												dotdata_for_record=[dotdata_ref1,dotdata_ref2,dotdata_alt]
										if float(min([rsquare_ref1[-1],rsquare_ref2[-1]]))==0:
											rsquare_alt[-1]+=1
											rsquare_ref1[-1]+=1
											rsquare_ref2[-1]+=1
										if float(rsquare_alt[-1]-min([rsquare_ref1[-1],rsquare_ref2[-1]]))/float(min([rsquare_ref1[-1],rsquare_ref2[-1]]))<rec_len_rev:
											if miss_hash_left[miss_rec]<seq_length_limit:
												rec_len_rev=float(rsquare_alt[-1]-min([rsquare_ref1[-1],rsquare_ref2[-1]]))/float(min([rsquare_ref1[-1],rsquare_ref2[-1]]))
												rec_name_rev=name_hash_left[miss_rec]
												rec_start_rev=miss_hash_left[miss_rec]
												seq1_rev=y
												dotdata_for_record_rev=[dotdata_ref1,dotdata_ref2,dotdata_alt]
								if rec_len>0:	
									if len(dotdata_for_record[0])>0:
										dotplot_subfigure_simple_long(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+'.alt.'+rec_name+'.png')
								if rec_len_rev<1:
									if len(dotdata_for_record_rev[0])>0:
										dotplot_subfigure_simple_long(window_size,seq1_rev,seq2[rec_start_rev:],seq3[rec_start_rev:],seq4[rec_start_rev:],out_path+sample_name+'.'+case_name+'.ref.'+rec_name_rev+'.png')
							if not read_hash_right==[]:
								miss_rec=-1
								rec_len=0
								new_all_reads_right=read_hash_minimize(all_reads_right)
								read_hash_right=new_all_reads_right[0]
								miss_hash_right=new_all_reads_right[1]
								name_hash_right=name_hash_modify(new_all_reads_right[2])
								for x in read_hash_right:
									miss_rec+=1
									y=x
									y2=miss_hash_right[miss_rec]
									y3=name_hash_right[miss_rec]
									dotdata_ref1=dotdata(window_size,y,seq2[::-1])
									dotdata_ref2=dotdata(window_size,y,seq3[::-1])
									dotdata_alt=dotdata(window_size,y,seq4[::-1])							
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref1)
									if not temp_rsquare==0:
										rsquare_ref1.append(temp_rsquare)
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref2)
									if not temp_rsquare==0:
										rsquare_ref2.append(temp_rsquare)
									temp_rsquare=eu_dis_calcu_simple_long(dotdata_alt)
									if not temp_rsquare==0:
										rsquare_alt.append(temp_rsquare)
									if not len(rsquare_ref1)==len(rsquare_ref2)==len(rsquare_alt):
										min_len=min([len(rsquare_ref1),len(rsquare_ref2),len(rsquare_alt)])
										rsquare_ref1=rsquare_ref1[:min_len]
										rsquare_ref2=rsquare_ref2[:min_len]
										rsquare_alt=rsquare_alt[:min_len]
									if not rsquare_ref2==[]:
										if max([rsquare_ref2[-1],rsquare_alt[-1]])-rsquare_ref1[-1]>rec_len:
											rec_len=max([rsquare_ref2[-1],rsquare_alt[-1]])-rsquare_ref1[-1]
											rec_name=name_hash_right[miss_rec]
											rec_start=miss_hash_right[miss_rec]
											dotdata_for_record=[dotdata_ref1,dotdata_ref2,dotdata_alt]
								if rec_len>0:
									if len(dotdata_for_record[0])>0:
										dotplot_subfigure_simple_long(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+rec_name+'.png')
							write_pacval_individual_stat_simple_long(txt_file,rsquare_ref1,rsquare_ref2,rsquare_alt,SV_index)
							remove_files_short(txt_file)
					else:
						fo=open(out_file_Cannot_Validate,'a')
						print >>fo, ' '.join([str(i) for i in info+junction])
						fo.close()
	def calcu_eu_dis_complex_short(out_path,sample_name,info,SV_index):
		#info=[k1,k2]+k3
		k1=info[0]
		k2=info[1]
		k3=info[2:]
		case_name='_'.join([str(i) for i in k3])
		txt_file=out_path+case_name+'.txt'
		ref_sv=info[0]
		alt_sv=info[1]
		chrom=info[2]
		bps=info[2:]
		flank_length=flank_length_calculate(bps)
		if bps_check(bps)==0:
			bl_len_hash=bl_len_hash_calculate(bps,ref_sv)
			end_point=end_point_calculate(alt_sv,bl_len_hash)
			all_reads=chop_pacbio_read_simple_short(info,flank_length)
			if not all_reads[0]==[]:
				all_reads_new=read_hash_minimize(all_reads)
				read_hash=all_reads_new[0]
				miss_hash=all_reads_new[1]
				name_hash=name_hash_modify(all_reads_new[2])
				rsquare_ref=[]
				rsquare_alt1=[]
				rsquare_alt2=[]
				rec_len=0
				rec_start=0
				rec_name='0'
				if not read_hash==[]:
					seqs=Pacbio_prodce_ref_alt_short(ref,flank_length,info)
					seq2=seqs[0]
					dotdata_qual_check=dotdata(window_size,seq2[flank_length:-flank_length],seq2[flank_length:-flank_length])
					region_QC=qual_check_repetitive_region(dotdata_qual_check)
					if region_QC[0]>region_QC_Cff or sum(region_QC[1])/float(len(seq2))<0.3:
						seq3=seqs[1]
						seq4=seqs[2]
						miss_rec=-1
						dotdata_for_record=[[],[],[]]
						seq1=''
						for x in read_hash:
							miss_rec+=1
							y=x
							y2=miss_hash[miss_rec]
							y3=name_hash[miss_rec]
							dotdata_ref=dotdata(window_size,y,seq2)
							dotdata_alt1=dotdata(window_size,y,seq3)
							dotdata_alt2=dotdata(window_size,y,seq4)							
							dotdata_ref_2=keep_diagnal_and_anti_diag_for_csv(dotdata_ref)
							dotdata_alt1_2=keep_diagnal_and_anti_diag_for_csv(dotdata_alt1)
							dotdata_alt2_2=keep_diagnal_and_anti_diag_for_csv(dotdata_alt2)
							#shift_ref=shift_diagnal_for_csv(dotdata_ref)
							#dotdata_ref_2=[[i[0],i[1]-shift_ref] for i in dotdata_ref_2]
							#shift_ref=shift_diagnal_for_csv(dotdata_alt1)
							#dotdata_alt1_2=[[i[0],i[1]-shift_ref] for i in dotdata_alt1_2]
							#shift_ref=shift_diagnal_for_csv(dotdata_alt2)
							#dotdata_alt2_2=[[i[0],i[1]-shift_ref] for i in dotdata_alt2_2]
							#eu_dis_calcu_check_dup(dotdata_ref,dotdata_alt1,dotdata_alt2,rsquare_ref,rsquare_alt1,rsquare_alt2,y2,delta,info)
							eu_dis_calcu_check_dup(dotdata_ref_2,dotdata_alt1_2,dotdata_alt2_2,rsquare_ref,rsquare_alt1,rsquare_alt2,y2,delta,info)
							if not len(rsquare_ref)==len(rsquare_alt1)==len(rsquare_alt2):
								min_len=min([len(rsquare_ref),len(rsquare_alt1),len(rsquare_alt2)])
								rsquare_ref=rsquare_ref[:min_len]
								rsquare_alt1=rsquare_alt1[:min_len]
								rsquare_alt2=rsquare_alt2[:min_len]
							if not rsquare_alt1==[]:
								if min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1]<rec_len:
									rec_len=min([rsquare_alt1[-1],rsquare_alt2[-1]])-rsquare_ref[-1]
									rec_start=y2
									rec_name=y3
									seq1=y
									dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
							else:
								seq1=y
						if rec_len==0:
							dotdata_for_record=[dotdata_ref,dotdata_alt1,dotdata_alt2]
							rec_name=y3
							rec_start=y2
							seq1=y
						if len(dotdata_for_record[0])>0:
							#dotplot(window_size,seq1,seq2,out_path+sample_name+'.'+case_name+'.ref.'+rec_name+'.png')
							#dotplot(window_size,seq1,seq3,out_path+sample_name+'.'+case_name+'.alt1.'+rec_name+'.png')
							#dotplot(window_size,seq1,seq4,out_path+sample_name+'.'+case_name+'.alt2.'+rec_name+'.png')
							#dotplot(window_size,seq2,seq2,out_path+sample_name+'.'+case_name+'.ref.QC.'+rec_name+'.png')							
							dotplot_subfigure_simple_short(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+rec_name+'.png')
							#write_dotfile(dotdata_for_record,rec_name,txt_file,rec_start)
							write_pacval_individual_stat_simple_short(txt_file,rsquare_ref,rsquare_alt1,rsquare_alt2,SV_index)
					else:
						fo=open(out_file_Cannot_Validate,'a')
						print >>fo, ' '.join([str(i) for i in info])
						fo.close()
			else:
				write_null_individual_stat(txt_file)
				remove_files_short(txt_file)
	def chromos_readin(ref):
		fin=open(ref+'.fai')
		chromos=[]
		for line in fin:
				pin=line.strip().split()
				chromos.append(pin[0])
		fin.close()
		return chromos
	def chop_pacbio_read_simple_short(info,flank_length):
		bps=info[2:]
		block_length={}
		for x in range(len(info[2:])-2):
			block_length[chr(97+x)]=int(info[x+4])-int(info[x+3])
		alA_len=numpy.sum([block_length[x] for x in info[1].split('/')[0] if not x=='^'])
		alB_len=numpy.sum([block_length[x] for x in info[1].split('/')[1] if not x=='^'])
		alRef_len=int(info[-1])-int(info[3])
		len_cff=max([alA_len,alB_len,alRef_len])
		if len_cff>10**4:
			len_cff=min([alA_len,alB_len,alRef_len])
		bam_in_new=bam_in_decide(bam_in,bps)
		if bam_in_new=='': return [[],[],[]]
		fbam=os.popen(r'''samtools view %s %s:%d-%d'''%(bam_in_new,bps[0],int(bps[1])-flank_length,int(bps[-1])+flank_length))
		out=[]
		out2=[]
		out3=[]
		tandem_test=[]
		for line in fbam:
			pbam=line.strip().split()
			if not pbam in tandem_test:
				tandem_test.append(pbam)
				#out3.append(int(pbam[3])-int(bps[1])+flank_length)
				if not pbam[0]=='@': 
					if int(pbam[3])<int(bps[1])-flank_length+1:
						align_info=cigar2alignstart(pbam[5],int(pbam[3]),bps,flank_length)
						align_start=align_info[0]
						miss_bp=align_info[1]+1
						if not miss_bp>flank_length/2:
							align_pos=int(pbam[3])
							target_read=pbam[9][align_start:]
							if len(target_read)>flank_length+len_cff:
								out.append(target_read[:max([alA_len,alB_len,alRef_len])+2*flank_length])
								out2.append(miss_bp)
								out3.append(pbam[0])
								#out3.append(pbam[:9])
					#elif int(pbam[3])<int(bps[1])+1:
					#	align_info=cigar2alignstart_2(pbam[5],int(pbam[3]),bps)
					#	align_start=align_info[0]
					#	miss_bp=align_info[1]+flank_length+1
					#	target_read=pbam[9][align_start:]
					#	if len(target_read)>len_cff:
					#		out.append(target_read[:max([alA_len,alB_len,alRef_len])+flank_length])
					#		out2.append(miss_bp)
					#		out3.append(pbam[0])
							#out3.append(pbam[:9])
		fbam.close()
		return [out,out2,out3]
	def chop_pacbio_read_left(bps,flank_length):
		#get reads align starts bps[1]-flank_length, and ends bps[1]+flank
		bam_in_new=bam_in_decide(bam_in,bps)
		if bam_in_new=='': return [[],[],[]]
		fbam=os.popen(r'''samtools view %s %s:%d-%d'''%(bam_in_new,bps[0],int(bps[1])-2*flank_length,int(bps[1])+flank_length))
		out=[]
		out2=[]
		out3=[]
		tandem_test=[]
		for line in fbam:
			pbam=line.strip().split()
			if not pbam in tandem_test:
				tandem_test.append(pbam)
				if not pbam[0]=='@': 
					if int(pbam[3])<int(bps[1])-flank_length+1:
						align_info=cigar2alignstart_left(pbam[5],int(pbam[3]),bps)
						align_start=align_info[0]
						miss_bp=align_info[1]+1
						#print [align_start,miss_bp]
						target_read=pbam[9][align_start:]
						if len(target_read)>2*flank_length and miss_bp<flank_length:
							out.append(target_read[:2*flank_length])
							out2.append(miss_bp)
							out3.append(pbam[0])
		fbam.close()
		return [out,out2,out3]
	def chop_pacbio_read_right(bps,flank_length):
		bam_in_new=bam_in_decide(bam_in,bps)
		if bam_in_new=='': return [[],[],[]]
		fbam=os.popen(r'''samtools view %s %s:%d-%d'''%(bam_in_new,bps[0],int(bps[2])-flank_length,int(bps[2])+flank_length))
		out=[]
		out2=[]
		out3=[]
		tandem_test=[]
		for line in fbam:
			pbam=line.strip().split()
			if not pbam in tandem_test:
				tandem_test.append(pbam)
				if not pbam[0]=='@': 
					if int(pbam[3])+int(cigar2reaadlength(pbam[5]))>int(bps[2])+flank_length-1:
						align_info=cigar2alignstart_right(pbam[5],int(pbam[3]),bps)
						align_end=align_info[0]
						miss_bp=align_info[1]+1
						target_read=pbam[9][:align_end]
						if len(target_read)>2*flank_length:
							out.append(target_read[::-1][:2*flank_length])
							out2.append(miss_bp)
							out3.append(pbam[0])
		fbam.close()
		return [out,out2,out3]
	def cigar2reaadlength(cigar):
		import re
		pcigar=re.compile(r'''(\d+)([MIDNSHP=X])''')
		cigars=[]
		for m in pcigar.finditer(cigar):
			cigars.append((m.groups()[0],m.groups()[1]))
		MapLen=0
		for n in cigars:
			if n[1]=='M' or n[1]=='D' or n[1]=='N':
				MapLen+=int(n[0])
		return MapLen
	def cigar2alignstart(cigar,start,bps,flank_length):
		#eg cigar2alignstart(pbam[5],int(pbam[3]),bps)
		import re
		pcigar=re.compile(r'''(\d+)([MIDNSHP=X])''')
		cigars=[]
		for m in pcigar.finditer(cigar):
			cigars.append((m.groups()[0],m.groups()[1]))
		read_rec=0
		align_rec=start
		for x in cigars:
			if x[1]=='S':
				read_rec+=int(x[0])
			if x[1]=='M':
				read_rec+=int(x[0])
				align_rec+=int(x[0])
			if x[1]=='D':
				align_rec+=int(x[0])
			if x[1]=='I':
				read_rec+=int(x[0])
			if align_rec>int(bps[1])-flank_length: break
		return [read_rec,int(align_rec)-int(bps[1])+flank_length]
	def cigar2alignstart_2(cigar,start,bps):
		#eg cigar2alignstart(pbam[5],int(pbam[3]),bps)
		import re
		pcigar=re.compile(r'''(\d+)([MIDNSHP=X])''')
		cigars=[]
		for m in pcigar.finditer(cigar):
			cigars.append((m.groups()[0],m.groups()[1]))
		read_rec=0
		align_rec=start
		for x in cigars:
			if x[1]=='S':
				read_rec+=int(x[0])
			if x[1]=='M':
				read_rec+=int(x[0])
				align_rec+=int(x[0])
			if x[1]=='D':
				align_rec+=int(x[0])
			if x[1]=='I':
				read_rec+=int(x[0])
			if align_rec>int(bps[1]): break
		return [read_rec,int(align_rec)-int(bps[1])]
	def cigar2alignstart_left(cigar,start,bps):
		#eg cigar2alignstart(pbam[5],int(pbam[3]),bps)
		import re
		pcigar=re.compile(r'''(\d+)([MIDNSHP=X])''')
		cigars=[]
		for m in pcigar.finditer(cigar):
			cigars.append((m.groups()[0],m.groups()[1]))
		read_rec=0
		align_rec=start
		for x in cigars:
			if x[1]=='S':
				read_rec+=int(x[0])
			if x[1]=='M':
				read_rec+=int(x[0])
				align_rec+=int(x[0])
			if x[1]=='D':
				align_rec+=int(x[0])
			if x[1]=='I':
				read_rec+=int(x[0])
			if align_rec>int(bps[1])-flank_length: break
		return [read_rec,int(align_rec)-int(bps[1])+flank_length]
	def cigar2alignstart_right(cigar,start,bps):
		#eg cigar2alignstart(pbam[5],int(pbam[3]),bps)
		import re
		pcigar=re.compile(r'''(\d+)([MIDNSHP=X])''')
		cigars=[]
		for m in pcigar.finditer(cigar):
			cigars.append((m.groups()[0],m.groups()[1]))
		read_rec=0
		align_rec=start
		for x in cigars:
			if x[1]=='S':
				read_rec+=int(x[0])
			if x[1]=='M':
				read_rec+=int(x[0])
				align_rec+=int(x[0])
			if x[1]=='D':
				align_rec+=int(x[0])
			if x[1]=='I':
				read_rec+=int(x[0])
			if align_rec>int(bps[2])+flank_length: break
		return [read_rec,-int(align_rec)+(int(bps[2])+flank_length)]
	def complementary(seq):
		seq2=[]
		for i in seq:
				if i in 'ATGCN':
						seq2.append('ATGCN'['TACGN'.index(i)])
				elif i in 'atgcn':
						seq2.append('atgcn'['tacgn'.index(i)])
		return ''.join(seq2)
	def cluster_simple_dis(y):
		temp=tranform_diagnal_to_horizonal(y)
		temp_hash=list_to_hash(temp)
		temp[0].sort()
		temp2=[temp[0][i+1]-temp[0][i] for i in range(len(temp[0])-1)]
		temp2_index=[i for i in range(len(temp2)) if temp2[i]>simple_dis_cff]
		if not temp2_index==[]:
			temp2_index=[-1]+temp2_index
			temp2_new=[temp[0][temp2_index[i]+1:temp2_index[i+1]+1] for i in range(len(temp2_index)-1)]
			temp2_new.append(temp[0][(temp2_index[-1]+1):])
			temp3_new=[]
			for y in temp2_new:
				temp3_new.append([])
				y2=list_unique(y)
				for z in y2:
					temp3_new[-1]+=temp_hash[z]
			temp4_new=[tranform_horizonal_to_diagnal([temp2_new[i],temp3_new[i]]) for i in range(len(temp2_new))]
			return temp4_new
		else:
			return [y]
	def cluter_to_diagnal(out):
	    #search for clusters according to diagnal. based on dis of a dot to diagnal:
	    out2=tranform_diagnal_to_horizonal(out)
	    out2_hash1={}
	    for k1 in range(len(out2[1])):
	        if not out2[1][k1] in out2_hash1.keys():
	            out2_hash1[out2[1][k1]]=[]
	        out2_hash1[out2[1][k1]].append(out2[0][k1])
	    cluster_a=cluster_numbers(out2_hash1.keys(),clu_dis_cff)
	    cluster_b=[]
	    for x in cluster_a:
	        cluster_b.append([])
	        for y in x:
	            cluster_b[-1]+=out2_hash1[y]
	    cluster_2_a=[]
	    cluster_2_b=[]
	    cluster_2_rest=[[],[]]
	    for x in range(len(cluster_b)):
	        if max(cluster_b[x])-min(cluster_b[x])>lenght_cff and len(cluster_b[x])>dots_num_cff:
	            cluster_2_a.append([])
	            for y in cluster_a[x]:
	                cluster_2_a[-1]+=[y for i in out2_hash1[y]]
	            cluster_2_b.append(cluster_b[x])
	        else:
	            cluster_2_rest[0]+=cluster_a[x]
	            cluster_2_rest[1]+=cluster_b[x]
	    diagnal_segs=[]
	    for x in range(len(cluster_2_a)):
	        diagnal_segs.append(tranform_horizonal_to_diagnal([cluster_2_b[x],cluster_2_a[x]]))
	def cluster_numbers(list,dis_cff):
	    out=[[]]
	    for k1 in sorted(list):
	        if out[-1]==[]:
	            out[-1].append(k1)
	        else:
	            if k1-out[-1][-1]<dis_cff:
	                out[-1].append(k1)
	            else:
	                out.append([k1])
	    return out
	def cluster_subgroup(cluster_a,point_dis_cff):
	    out=[[]]
	    for x in sorted(cluster_a):
	        if out[-1]==[]:
	            out[-1].append(x)
	        else:
	            if x-out[-1][-1]<point_dis_cff:
	                out[-1].append(x)
	            else:
	                out.append([x])
	    return out
	def cluster_check(cluster_a,cluster_b):
	    out=[[],[]]
	    rec=-1
	    for x in cluster_b:
	        rec+=1
	        temp_out=cluster_subgroup(x,point_dis_cff)
	        if len(temp_out)==1:
	            out[0].append(cluster_a[rec])
	            out[0].append()
	def cluster_dis_to_diagnal(out):
		out1=tranform_diagnal_to_distance(out)
		out1_hash=list_to_hash(out1)
		cluster_a=cluster_numbers(out1[0],clu_dis_cff)
		out_clustered=[]
		out_left=[[],[]]
		for x in cluster_a:
			if len(x)>dots_num_cff:
				x2=list_unique(x)
				out_clustered.append([[],[]])
				for y in x2:
					for z in out1_hash[y]:
						out_clustered[-1][0].append(out[0][z])
						out_clustered[-1][1].append(out[1][z])
			else:
				x2=list_unique(x)
				for y in x2:
					for z in out1_hash[y]:
						out_left[0].append(out[0][z])
						out_left[1].append(out[1][z])
		out2=tranform_anti_diagnal_to_distance(out_left)			
		out2_hash=list_to_hash(out2)
		cluster_b=cluster_numbers(out2[0],clu_dis_cff)
		out_anti_diag=[]
		for x in cluster_b:
			if len(x)>dots_num_cff:
				x2=list_unique(x)
				out_anti_diag.append([[],[]])
				for y in x2:
					for z in out2_hash[y]:
						out_anti_diag[-1][0].append(out_left[0][z])
						out_anti_diag[-1][1].append(out_left[1][z])
		return [out_clustered,out_anti_diag]
	def cluster_dots_based_simplely_on_dis(data_list,simple_dis_cff):
		#subgroups dots based on their distance on x-axil first, and then on y-axil. distance >50 would be used as the cutoff.
		out=[]
		for x in data_list:
			y=k_means_cluster_Predict(x,info)
			out+=y
		return out
	def cluster_range_decide(other_cluster):
		out=[]
		for x in other_cluster:
			out.append([])
			out[-1].append([min(x[0]),max(x[0])])
			out[-1].append([min(x[1]),max(x[1])])
		return out
	def cluster_size_decide(range_cluster):
		out=[]
		for x in range_cluster:
			size=(x[0][1]-x[0][0])*(x[1][1]-x[1][0])
			out.append(numpy.sqrt(size))
		return out
	def compute_bic(kmeans,X):
		"""
		Computes the BIC metric for a given clusters
		Parameters:
		-----------------------------------------
		kmeans:  List of clustering object from scikit learn
		X     :  multidimension np array of data points
		Returns:
		-----------------------------------------
		BIC value
		"""
		# assign centers and labels
		centers = [kmeans.cluster_centers_]
		labels  = kmeans.labels_
		#number of clusters
		m = kmeans.n_clusters
		# size of the clusters
		n = np.bincount(labels)
		#size of data set
		N, d = X.shape
		#compute variance for all clusters beforehand
		cl_var=[]
		for i in xrange(m):
			if not n[i] - m==0:
				cl_var.append((1.0 / (n[i] - m)) * sum(distance.cdist(X[np.where(labels == i)], [centers[0][i]], 'euclidean')**2))
			else:
				cl_var.append(float(10**20) * sum(distance.cdist(X[np.where(labels == i)], [centers[0][i]], 'euclidean')**2))
		const_term = 0.5 * m * np.log10(N)
		BIC = np.sum([n[i] * np.log10(n[i]) -
		       n[i] * np.log10(N) -
		     ((n[i] * d) / 2) * np.log10(2*np.pi) -
		      (n[i] / 2) * np.log10(cl_var[i]) -
		     ((n[i] - m) / 2) for i in xrange(m)]) - const_term
		return(BIC)
	def data_re_format(dotdata_ref):
		out=[[],[]]
		for x in dotdata_ref:
			out[0].append(x[0])
			out[1].append(x[1])
		return out
	def decide_bp_temp(chrom,junction,bp_let_hash):
		if not '^' in junction[0] and not '^' in junction[1]:
			bp_temp_info=[chrom,bp_let_hash[junction[0]][1],bp_let_hash[junction[1]][0]]
		elif '^' in junction[0] and not '^' in junction[1]:
			bp_temp_info=[chrom,bp_let_hash[junction[0]][0],bp_let_hash[junction[1]][0]]
		elif not '^' in junction[0] and '^' in junction[1]:
			bp_temp_info=[chrom,bp_let_hash[junction[0]][1],bp_let_hash[junction[1]][1]]
		elif  '^' in junction[0] and'^' in junction[1]:
			bp_temp_info=[chrom,bp_let_hash[junction[0]][0],bp_let_hash[junction[1]][1]]
		return bp_temp_info
	def decide_main_diagnal(dis_info):
		temp=[len(x[0]) for x in dis_info[0]]
		temp_index=temp.index(max(temp))
		temp_info=dis_info[0][temp_index]
		x_y_dis=[temp_info[1][x]-temp_info[0][x] for x in range(len(temp_info[0]))]
		return numpy.median(x_y_dis)
	def dotdata(kmerlen,seq1, seq2):
		# parse command-line arguments
		if len(sys.argv) < 4:
			#print "you must call program as:  "
			#print "   python ps1-dotplot.py <KMER LEN> <FASTA 1> <FASTA 2> <PLOT FILE>"
			#print "   PLOT FILE may be *.ps, *.png, *.jpg"
			sys.exit(1)
		# match every nth base. Or set to 0 to allow third base mismatches
		nth_base = 1
		inversions = True
		hits = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
		return hits
	def dotdata_write(plotfile,hits_list):
		fo=open(plotfile,'w')
		for x in hits_list:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
	def dotplot_subfigure_simple_short(kmerlen,seq1,seq2,seq3,seq4,figurename):
		nth_base = 1
		inversions = True
		hits_ref_ref = kmerhits(seq2, seq2, kmerlen, nth_base, inversions)
		hits_ref = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
		hits_alt1 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
		hits_alt2 = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		if float(len(hits_ref))/float(len(hits_ref_ref))<0.1:
			kmerlen_new=int(0.8*kmerlen)
			hits_ref = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
			hits_alt1 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
			hits_alt2 = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		elif float(len(hits_ref))/float(len(hits_ref_ref))>10:
			kmerlen_new=int(1.2*kmerlen)
			hits_ref = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
			hits_alt1 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
			hits_alt2 = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		fig=plt.figure(plt_figure_index)
		makeDotplot_subfigure(hits_ref_ref,'ref vs. ref',221)
		makeDotplot_subfigure(hits_ref,'read vs. ref',222)
		makeDotplot_subfigure(hits_alt1,'read vs. allele1',223)
		makeDotplot_subfigure(hits_alt2,'read vs. allele2',224)
		plt.savefig(figurename)
		#plt.show()
		plt.close(fig)
	def dotplot_subfigure_simple_long(kmerlen,seq1,seq2,seq3,seq4,figurename):
		nth_base = 1
		inversions = True
		hits_ref_ref = kmerhits(seq2, seq2, kmerlen, nth_base, inversions)
		hits_ref1 = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
		hits_ref2 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
		hits_alt = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		if float(len(hits_ref1))/float(len(hits_ref_ref))<0.1:
			kmerlen_new=int(0.8*kmerlen)
			hits_ref1 = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
			hits_ref2 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
			hits_alt = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		elif float(len(hits_ref1))/float(len(hits_ref_ref))>10:
			kmerlen_new=int(1.2*kmerlen)
			hits_ref1 = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
			hits_ref2 = kmerhits(seq1, seq3, kmerlen, nth_base, inversions)
			hits_alt = kmerhits(seq1, seq4, kmerlen, nth_base, inversions)
		fig=plt.figure(plt_figure_index)
		makeDotplot_subfigure(hits_ref_ref,'ref vs. ref',221)
		makeDotplot_subfigure(hits_alt,'read vs. alt_junction',222)
		makeDotplot_subfigure(hits_ref1,'read vs. ref_left',223)
		makeDotplot_subfigure(hits_ref2,'read vs. ref_right',224)
		plt.savefig(figurename)
		#plt.show()
		plt.close(fig)
	def dotplot(kmerlen,seq1,seq2,plotfile):
		nth_base = 1
		inversions = True
		hits = kmerhits(seq1, seq2, kmerlen, nth_base, inversions)
		p = makeDotplot(plotfile, hits, len(seq1), len(seq2))
	def dup_decide(structure):
		flag=0
		for x in structure:
			if not x=='^':
				if structure.count(x)>1:
					flag+=1
		return flag
	def end_point_calculate(alt_sv,bl_len_hash):
		end_point=0
		for x in alt_sv.split('/')[0]:
			if not x=='^':
				end_point+=bl_len_hash[x]
		return end_point
	def eu_dis_calcu_1(fo_ref,rsquare_ref,align_off,delta):
		#this function calculates total distance of dots to diagnal, with direction considered; smaller = better ;  especially designed for duplcations;
		temp_data1=[[],[]]
		for x in fo_ref:
			temp_data1[0].append(int(x[0])-align_off)
			temp_data1[1].append(int(x[1]))
		if not temp_data1[0]==[]:
			out=sum([temp_data1[1][x]-temp_data1[0][x] for x in range(len(temp_data1[0]))])
			rsquare_ref.append(abs(out))
	def eu_dis_calcu_2(fo_ref,rsquare_ref,align_off,delta):
		#this function calculates total distance of dots to diagnal; smaller = better ; not suitable for duplications
		temp_data1=[[],[]]
		for x in fo_ref:
			temp_data1[0].append(int(x[0])-align_off)
			temp_data1[1].append(int(x[1]))
		if not temp_data1[0]==[]:
			out=sum([abs(temp_data1[1][x]-temp_data1[0][x]) for x in range(len(temp_data1[0]))])
			rsquare_ref.append(abs(out))
	def eu_dis_calcu_3a(fo_ref,rsquare_ref,align_off,delta):
		#this function calculates total distance of dots to diagnal; smaller = better
		fo1=open(fo_ref+'.txt')
		temp_data1=[[],[]]
		for line in fo1:
			po1=line.strip().split()
			temp_data1[0].append(int(po1[0])-align_off)
			temp_data1[1].append(int(po1[1]))
		fo1.close()
		rec1=1
		for x in range(len(temp_data1[0])):
			if abs(temp_data1[1][x]-temp_data1[0][x])<float(temp_data1[0][x])/10.0:
				rec1+=1
		rsquare_ref.append(float(len(temp_data1[0]))/float(rec1))
	def eu_dis_calcu_3(fo_ref,rsquare_ref,align_off,delta):
		#count total #dots/#dots locates close to diagnal; smaller = better
		#either diagnal or reverse diganal
		fo1=open(fo_ref+'.txt')
		temp_data1=[[],[]]
		for line in fo1:
			po1=line.strip().split()
			temp_data1[0].append(int(po1[0])-align_off)
			temp_data1[1].append(int(po1[1]))
		fo1.close()
		temp_data1.append(temp_data1[1][::-1])
		rec1=1
		for x in range(len(temp_data1[0])):
			if abs(temp_data1[1][x]-temp_data1[0][x])<float(temp_data1[0][x])/10.0:
				rec1+=1
		rec2=1
		for x in range(len(temp_data1[0])):
			if abs(temp_data1[2][x]-temp_data1[0][x])<float(temp_data1[0][x])/10.0:
				rec2+=1
		rsquare_ref.append(float(len(temp_data1[0]))/float(rec1))
	def eu_dis_calcu_simple_long(fo_ref):
		#return number of dots falling within 10# dis to diagnal
		temp_data1=[[],[]]
		for x in fo_ref:
			temp_data1[0].append(int(x[0]))
			temp_data1[1].append(int(x[1]))
		temp_data2=[[],[]]
		for x in range(len(temp_data1[0])):
			if numpy.abs(temp_data1[0][x]-temp_data1[1][x])<float(temp_data1[0][x])/10.0:
				temp_data2[0].append(temp_data1[0][x])
				temp_data2[1].append(temp_data1[1][x])			
		return len(temp_data2[0])
	def eu_dis_calcu_check_dup(fo_ref,fo1_alt,fo2_alt,rsquare_ref,rsquare_alt1,rsquare_alt2,y2,delta,info):
		#Calculate total distance of all dots to diagnal; smaller=better.
		structure1=info[0].split('/')[0]
		structure2=info[1].split('/')[0]
		structure3=info[1].split('/')[1]
		if sum([int(dup_decide(structure1)),int(dup_decide(structure2)),int(dup_decide(structure3))])>0:
				eu_dis_calcu_1(fo_ref,rsquare_ref,y2,delta)
				eu_dis_calcu_1(fo1_alt,rsquare_alt1,y2,delta)
				eu_dis_calcu_1(fo2_alt,rsquare_alt2,y2,delta)
		else:
				eu_dis_calcu_2(fo_ref,rsquare_ref,y2,delta)
				eu_dis_calcu_2(fo1_alt,rsquare_alt1,y2,delta)
				eu_dis_calcu_2(fo2_alt,rsquare_alt2,y2,delta)
	def file_initiate(file):
		if not os.path.isfile(file):
			fo=open(file,'w')
			fo.close()
	def flank_length_calculate(bps):
		if int(bps[-1])-int(bps[1])<100:
			flank_length=2*(int(bps[-1])-int(bps[1]))
		else:
			if int(bps[-1])-int(bps[1])<500:
				flank_length=int(bps[-1])-int(bps[1])
			else:
				flank_length=500
		return flank_length
	def junc_check(junction,k1):
		test=['left']+[i for i in k1.split('/')[0]]+['right']
		test=[i+'^' for i in test[::-1]]+test
		dis=test.index(junction[1])-test.index(junction[0])
		return dis
	def keep_diagnal_and_anti_diag_for_csv(dotdata_ref):
		out=data_re_format(dotdata_ref)
		dis_info=cluster_dis_to_diagnal(out)
		out=[]
		for x in dis_info:
			for y in x:
				for z in range(len(y[0])):
					out.append([y[0][z],y[1][z]])
		return out
	def kmerhits(seq1, seq2, kmerlen, nth_base=1, inversions=False):
		# hash table for finding hits
		lookup = {}
		# store sequence hashes in hash table
		#print "hashing seq1..."
		seq1len = len(seq1)
		for i in xrange(seq1len - kmerlen + 1):
			key = seq1[i:i+kmerlen]
			for subkey in subkeys(key, nth_base, inversions):
				lookup.setdefault(subkey, []).append(i)
		# match every nth base by 
		# look up hashes in hash table
		#print "hashing seq2..."
		hits = []
		for i in xrange(len(seq2) - kmerlen + 1):
			key = seq2[i:i+kmerlen]
			# only need to specify inversions for one seq
			for subkey in subkeys(key, nth_base, False):
				subhits = lookup.get(subkey, [])
				if subhits != []:
					# store hits to hits list
					for hit in subhits:
						hits.append((i, hit))
					# break out of loop to avoid doubly counting
					# exact matches
					break
		return hits
	def k_means_cluster(data_list):
		#print data_list
		array_diagnal=array([[data_list[0][x],data_list[1][x]] for x in range(len(data_list[0]))])
		ks = range(1,min([5,len(data_list[0])+1]))
		KMeans = [cluster.KMeans(n_clusters = i, init="k-means++").fit(array_diagnal) for i in ks]
		BIC = [compute_bic(kmeansi,array_diagnal) for kmeansi in KMeans]
		ks_picked=ks[BIC.index(max(BIC))]
		if ks_picked==1:
			return [data_list]
		else:
			out=[]
			std_rec=[scipy.std(data_list[0]),scipy.std(data_list[1])]
			whitened = whiten(array_diagnal)
			centroids, distortion=kmeans(whitened,ks_picked)
			idx,_= vq(whitened,centroids)
			for x in range(ks_picked):
				group1=[[int(i) for i in array_diagnal[idx==x,0]],[int(i) for i in array_diagnal[idx==x,1]]]
				out.append(group1)
			return out
	def k_means_cluster(data_list):
		if max(data_list[0])-min(data_list[0])>10 and max(data_list[1])-min(data_list[1])>10:
			array_diagnal=array([[data_list[0][x],data_list[1][x]] for x in range(len(data_list[0]))])
			ks = range(1,min([5,len(data_list[0])+1]))
			KMeans = [cluster.KMeans(n_clusters = i, init="k-means++").fit(array_diagnal) for i in ks]
			KMeans_predict=[cluster.KMeans(n_clusters = i, init="k-means++").fit_predict(array_diagnal) for i in ks]
			BIC=[]
			BIC_rec=[]
			for x in ks:
				if KMeans_predict[x-1].max()<x-1: continue
				else:
					BIC_i=compute_bic(KMeans[x-1],array_diagnal)
					if abs(BIC_i)<10**8:
						BIC.append(BIC_i)
						BIC_rec.append(x)
			#BIC = [compute_bic(kmeansi,array_diagnal) for kmeansi in KMeans]
			#ks_picked=ks[BIC.index(max(BIC))]
			ks_picked=BIC_rec[BIC.index(max(BIC))]
			if ks_picked==1:
				return [data_list]
			else:
				out=[]
				std_rec=[scipy.std(data_list[0]),scipy.std(data_list[1])]
				whitened = whiten(array_diagnal)
				centroids, distortion=kmeans(whitened,ks_picked)
				idx,_= vq(whitened,centroids)
				for x in range(ks_picked):
					group1=[[int(i) for i in array_diagnal[idx==x,0]],[int(i) for i in array_diagnal[idx==x,1]]]
					out.append(group1)
				return out
		else:
			return [data_list]
	def k_means_cluster_Predict(data_list,info):
		array_diagnal=array([[data_list[0][x],data_list[1][x]] for x in range(len(data_list[0]))])
		ks = range(1,len(info))
		KMeans = [cluster.KMeans(n_clusters = i, init="k-means++").fit(array_diagnal) for i in ks]
		BIC = [compute_bic(kmeansi,array_diagnal) for kmeansi in KMeans]
		ks_picked=ks[BIC.index(max(BIC))]
		if ks_picked==1:
			return [data_list]
		else:
			out=[]
			std_rec=[scipy.std(data_list[0]),scipy.std(data_list[1])]
			whitened = whiten(array_diagnal)
			centroids, distortion=kmeans(whitened,ks_picked)
			idx,_= vq(whitened,centroids)
			for x in range(ks_picked):
				group1=[[int(i) for i in array_diagnal[idx==x,0]],[int(i) for i in array_diagnal[idx==x,1]]]
				out.append(group1)
			return out
	def let_to_letters(k2):
		letters=[[]]
		for x in k2:
			if not x in ['^','/']:
				letters[-1].append([x])
			elif x=='/':
				letters.append([])
			elif x=='^':
				letters[-1][-1][-1]+=x
		letters[0]=[['left']]+letters[0]+[['right']]
		letters[1]=[['left']]+letters[1]+[['right']]
		return letters
	def list_to_hash(out):
		out_hash={}
		for x in range(len(out[0])):
			if not out[0][x] in out_hash.keys():
				out_hash[out[0][x]]=[]
			out_hash[out[0][x]].append(out[1][x])
		return out_hash
	def list_unique(list):
		out=[]
		for x in list:
			if not x in out:
				out.append(x)
		return out
	def makeDotplot(filename, hits, lenSeq1, lenSeq2):
		#"""generate a dotplot from a list of hits filename may end in the following file extensions: *.ps, *.png, *.jpg"""
		if len(hits)==0: 
			#print hits
			return ' '
		x, y = zip(* hits)
		slope1 = 1.0e6 / (825000 - 48000)
		slope2 = 1.0e6 / (914000 - 141000)
		offset1 = 0 - slope1*48000
		offset2 = 0 - slope2*141000
		hits2 = quality(hits)
		#print "%.5f%% hits on diagonal" % (100 * len(hits2) / float(len(hits)))
		# create plot
		p = plotting.Gnuplot()
		p.enableOutput(False)
		p.plot(x, y, xlab="sequence 2", ylab="sequence 1")
		p.plotfunc(lambda x: slope1 * x + offset1, 0, 1e6, 1e5)
		p.plotfunc(lambda x: slope2 * x + offset2, 0, 1e6, 1e5)
		# set plot labels
		p.set(xmin=0, xmax=lenSeq2, ymin=0, ymax=lenSeq1)
		p.set(main="dotplot (%d hits, %.5f%% hits on diagonal)" %
			  (len(hits), 100 * len(hits2) / float(len(hits))))
		p.enableOutput(True)
		# output plot
		p.save(filename)
		return p
	def makeDotplot_subfigure(hits, title,figure_pos):
		#"""generate a dotplot from a list of hits filename may end in the following file extensions: *.ps, *.png, *.jpg"""
		if len(hits)==0: 
			#print hits
			return ' '
		x, y = zip(* hits)
		slope1 = 1.0e6 / (825000 - 48000)
		slope2 = 1.0e6 / (914000 - 141000)
		offset1 = 0 - slope1*48000
		offset2 = 0 - slope2*141000
		hits2 = quality(hits)
		xlib_range=int(float(max(x))/float(10**(len(str(max(x)))-1)))+1
		if xlib_range<3:
			xlib=[(i+1)*10**(len(str(max(x)))-1) for i in range(xlib_range)]
			xlib_new=[xlib[0]/2]
			for xi in range(len(xlib)-1):
				xlib_new.append(xlib_new[0]*(2*(xi+1)+1))
			xlib+=xlib_new
			xlib.sort()
		elif xlib_range<5:
			xlib=[(i+1)*10**(len(str(max(x)))-1) for i in range(xlib_range)]
		else:
			xlib=[(i+1)*2*10**(len(str(max(x)))-1) for i in range(xlib_range/2+1)]
		plt.subplot(figure_pos)
		plt.plot(x, y,'+',color='r')
		plt.xticks(xlib, [str(i) for i in xlib])
		plt.title(title)
		plt.grid(False)
		#print "%.5f%% hits on diagonal" % (100 * len(hits2) / float(len(hits)))
		# create plot
	def name_hash_modify(name_hash):
		out=[]
		for x in name_hash:
			if '/' in x:
				y=x.replace('/','-')
			else:
				y=x
			out.append(y)
		return out
	def path_mkdir(path):
			if not os.path.isdir(path):
					os.system(r'''mkdir %s'''%(path))
	def path_modify(path):
		if not path[-1]=='/':
			path+='/'
		return path
	def Pacbio_prodce_ref_alt_short(ref,flank_length,info):
		#fin=open(txt_file)
		#pin=fin.readline().strip().split()
		#fin.close()
		pin=info
		ref_sv=pin[0]
		ref_sv='/'.join(['1'+ref_sv.split('/')[0]+'2','1'+ref_sv.split('/')[0]+'2'])
		alt_sv=pin[1]
		alt_sv='/'.join(['1'+alt_sv.split('/')[0]+'2','1'+alt_sv.split('/')[1]+'2'])
		chrom=pin[2]
		bps=pin[2:]
		bps=[bps[0]]+[str(int(bps[1])-flank_length)]+bps[1:]+[str(int(bps[-1])+flank_length)]
		ref_hash={}
		rec=0
		for x in ref_sv.split('/')[0]:
			rec+=1
			fref=os.popen(r'''samtools faidx %s %s:%d-%d'''%(ref,chrom,int(bps[rec]), int(bps[rec+1])))
			fref.readline().strip().split()
			seq=''
			while True:
					pref=fref.readline().strip().split()
					if not pref: break
					seq+=pref[0]
			fref.close()
			ref_hash[x]=seq
		ref_hash=ref_hash_modi(ref_hash)
		alt_sv_list=alt_sv_to_list(alt_sv)
		ref_seq=''.join([ref_hash[x] for x in ref_sv.split('/')[0]])
		alt_1_seq=''.join([ref_hash[x] for x in alt_sv_list[0]])
		alt_2_seq=''.join([ref_hash[x] for x in alt_sv_list[1]])
		return [upper_string(ref_seq),upper_string(alt_1_seq),upper_string(alt_2_seq)]
	def Pacbio_prodce_ref_alt_ins_short(ref,flank_length,info):
		ref_sv='12/12'
		alt_sv='1'+info[1].split('/')[0].replace('a','').replace('c','')+'2/1'+info[1].split('/')[1].replace('a','').replace('c','')+'2'
		chrom=info[2]
		bps=info[2:]
		bps=[bps[0],str(int(bps[1])-flank_length),bps[1],str(int(bps[1])+flank_length)]
		ref_hash={}
		rec=0
		for x in ref_sv.split('/')[0]:
			rec+=1
			fref=os.popen(r'''samtools faidx %s %s:%d-%d'''%(ref,chrom,int(bps[rec]), int(bps[rec+1])))
			fref.readline().strip().split()
			seq=''
			while True:
					pref=fref.readline().strip().split()
					if not pref: break
					seq+=pref[0]
			fref.close()
			ref_hash[x]=seq
		ref_hash['b']=''.join(['N' for i in range(info[4]-info[3])])
		ref_hash=ref_hash_modi(ref_hash)
		alt_sv_list=alt_sv_to_list(alt_sv)
		ref_seq=''.join([ref_hash[x] for x in ref_sv.split('/')[0]])
		alt_1_seq=''.join([ref_hash[x] for x in alt_sv_list[0]])
		alt_2_seq=''.join([ref_hash[x] for x in alt_sv_list[1]])
		return [upper_string(ref_seq),upper_string(alt_1_seq),upper_string(alt_2_seq)]
	def Pacbio_prodce_ref_alt_junc(ref,flank_length,info,junction,bp_let_hash):
		chrom=info[2]
		ref_hash={}
		if not '^' in junction[0] and not '^' in junction[1]:
			#['a','c']
			bps=[chrom,bp_let_hash[junction[0]][1]-flank_length,bp_let_hash[junction[0]][1],bp_let_hash[junction[1]][0],bp_let_hash[junction[1]][0]+flank_length]
			bps_left=[chrom,bp_let_hash[junction[0]][1]]
			bps_right=[chrom,bp_let_hash[junction[1]][0]]
			ref_hash[junction[0]+'_ri']=ref_seq_readin(ref,chrom,int(bps[1]),int(bps[2]),'FALSE')
			ref_hash[junction[1]+'_le']=ref_seq_readin(ref,chrom,int(bps[3]),int(bps[4]),'FALSE')
		elif '^' in junction[0] and not '^' in junction[1]:
			#['a^','c']
			bps=[chrom,bp_let_hash[junction[0]][0],bp_let_hash[junction[0]][0]+flank_length,bp_let_hash[junction[1]][0],bp_let_hash[junction[1]][0]+flank_length]
			bps_left=[chrom,bp_let_hash[junction[0]][0]]
			bps_right=[chrom,bp_let_hash[junction[1]][0]]
			ref_hash[junction[0]+'_ri']=ref_seq_readin(ref,chrom,int(bps[1]),int(bps[2]),'TRUE')
			ref_hash[junction[1]+'_le']=ref_seq_readin(ref,chrom,int(bps[3]),int(bps[4]),'FALSE')
		elif not '^' in junction[0] and '^' in junction[1]:
			#['a','c^']
			bps=[chrom,bp_let_hash[junction[0]][1]-flank_length,bp_let_hash[junction[0]][1],bp_let_hash[junction[1]][1]-flank_length,bp_let_hash[junction[1]][1]]
			bps_left=[chrom,bp_let_hash[junction[0]][1]]
			bps_right=[chrom,bp_let_hash[junction[1]][1]]
			ref_hash[junction[0]+'_ri']=ref_seq_readin(ref,chrom,int(bps[1]),int(bps[2]),'FALSE')
			ref_hash[junction[1]+'_le']=ref_seq_readin(ref,chrom,int(bps[3]),int(bps[4]),'TRUE')
		elif '^' in junction[0] and '^' in junction[1]:
			#['a^','c^']
			bps=[chrom,bp_let_hash[junction[0]][0],bp_let_hash[junction[0]][0]+flank_length,bp_let_hash[junction[1]][1]-flank_length,bp_let_hash[junction[1]][1]]			
			bps_left=[chrom,bp_let_hash[junction[0]][0]]
			bps_right=[chrom,bp_let_hash[junction[1]][1]]
			ref_hash[junction[0]+'_ri']=ref_seq_readin(ref,chrom,int(bps[1]),int(bps[2]),'TRUE')
			ref_hash[junction[1]+'_le']=ref_seq_readin(ref,chrom,int(bps[3]),int(bps[4]),'TRUE')
		ref_hash['ref_le']=ref_seq_readin(ref,chrom,bps_left[1]-flank_length,bps_left[1]+flank_length,'FALSE')
		ref_hash['ref_ri']=ref_seq_readin(ref,chrom,bps_right[1]-flank_length,bps_right[1]+flank_length,'FALSE')
		return [upper_string(ref_hash['ref_le']),upper_string(ref_hash['ref_ri']),upper_string(ref_hash[junction[0]+'_ri']+ref_hash[junction[1]+'_le'])]
		#return [ref1,ref2,alt]
	def Pacbio_prodce_ref_alt_multi_chrom(ref,flank_length,k1):
		#eg of k1:['22', '50934615', 'chr22', 50567289, 50567789, '', '22', 50934615, 50935115, '.', '.']
		chrom=k1[0]
		ref_hash={}
		alt_a=k1[2:5]
		alt_b=k1[6:9]
		reverse_flag=[]
		for i in k1[9:]:
			if i=='.':
				reverse_flag.append('FALSE')
			elif i=='^':
				reverse_flag.append('TRUE')
			else:
				print 'Error: wrong k1 info, reverse not properly stated.'
		if reverse_flag==['FALSE','FALSE']: 
			ref_seq_a=ref_seq_readin(ref,chrom,int(alt_a[2])-flank_length,int(alt_a[2])+flank_length,'FALSE')
			ref_seq_b=ref_seq_readin(ref,chrom,int(alt_b[1])-flank_length,int(alt_b[1])+flank_length,'FALSE')
			ref_seq_a2=ref_seq_readin(ref,chrom,int(alt_a[2])-flank_length,int(alt_a[2]),'FALSE')
			ref_seq_b2=ref_seq_readin(ref,chrom,int(alt_b[1]),int(alt_b[1])+flank_length,'FALSE')
		elif reverse_flag==['FALSE','TRUE']:
			ref_seq_a=ref_seq_readin(ref,chrom,int(alt_a[2])-flank_length,int(alt_a[2])+flank_length,'FALSE')
			ref_seq_b=ref_seq_readin(ref,chrom,int(alt_b[2])-flank_length,int(alt_b[2])+flank_length,'FALSE')
			ref_seq_a2=ref_seq_readin(ref,chrom,int(alt_a[2])-flank_length,int(alt_a[2]),'FALSE')
			ref_seq_b2=ref_seq_readin(ref,chrom,int(alt_b[2])-flank_length,int(alt_b[2]),'FALSE')
		elif reverse_flag==['TRUE','FALSE']:
			ref_seq_a=ref_seq_readin(ref,chrom,int(alt_a[1])-flank_length,int(alt_a[1])+flank_length,'FALSE')
			ref_seq_b=ref_seq_readin(ref,chrom,int(alt_b[1])-flank_length,int(alt_b[1])+flank_length,'FALSE')
			ref_seq_a2=ref_seq_readin(ref,chrom,int(alt_a[1]),int(alt_a[1])+flank_length,'FALSE')
			ref_seq_b2=ref_seq_readin(ref,chrom,int(alt_b[1]),int(alt_b[1])+flank_length,'FALSE')
		alt_seq=ref_seq_readin(ref,chrom,int(alt_a[1]),int(alt_a[2]),reverse_flag[0])+ref_seq_readin(ref,chrom,int(alt_b[1]),int(alt_b[2]),reverse_flag[1])
		return [ref_seq_a,ref_seq_b,alt_seq,ref_seq_a2,ref_seq_b2]
	def Pacbio_prodce_ref_alt_long(ref,new_structure_single,txt_file):
		#eg: new_structure_single=new_structure[0]
		x=new_structure_single
		struc_hash={}
		struc_hash[x[0][0]]=''
		struc_hash[x[0][0]+'^']=''
		fread1=os.popen(r'''samtools faidx %s %s:%d-%d'''%(ref,x[2][0],x[2][1],x[2][2]))
		pin=fread1.readline().strip().split()
		for line in fread1:
			pin=line.strip().split()
			struc_hash[x[0][0]]+=pin[0]
		fread1.close()
		struc_hash[x[0][0]+'^']=reverse(complementary(struc_hash[x[0][0]]))
		struc_hash[x[1][0]]=''
		struc_hash[x[1][0]+'^']=''
		fread1=os.popen(r'''samtools faidx %s %s:%d-%d'''%(ref,x[3][0],x[3][1],x[3][2]))
		pin=fread1.readline().strip().split()
		for line in fread1:
			pin=line.strip().split()
			struc_hash[x[1][0]]+=pin[0]
		fread1.close()
		struc_hash[x[1][0]+'^']=reverse(complementary(struc_hash[x[1][0]]))
		fo1=open('.'.join(txt_file.split('.')[:-1])+'.alt.fa','w')
		print >>fo1, '_'.join([str(i) for i in [x[0],x[1]]+x[2]+x[3]])
		new_seq=''
		for y in x[:2]:
			new_seq+=struc_hash[y]
		for y in chop_x_for_fasta(new_seq):
			print >>fo1,y
		fo1.close()
		os.system(r'''samtools faidx %s %s:%d-%d > %s'''%(ref,x[2][0],x[2][1],x[2][1]+2*flank_length,'.'.join(txt_file.split('.')[:-1])+'.ref1.fa'))
		os.system(r'''samtools faidx %s %s:%d-%d > %s'''%(ref,x[3][0],x[3][1],x[3][1]+2*flank_length,'.'.join(txt_file.split('.')[:-1])+'.ref2.fa'))
		return ['.'.join(txt_file.split('.')[:-1])+'.alt.fa','.'.join(txt_file.split('.')[:-1])+'.ref1.fa','.'.join(txt_file.split('.')[:-1])+'.ref2.fa']
	def quality(hits):
		"""determines the quality of a list of hits"""
		slope1 = 1.0e6 / (825000 - 48000)
		slope2 = 1.0e6 / (914000 - 141000)
		offset1 = 0 - slope1*48000
		offset2 = 0 - slope2*141000
		goodhits = []
		for hit in hits:
			upper = slope1 * hit[0] + offset1
			lower = slope2 * hit[0] + offset2
			if lower < hit[1] < upper:
				goodhits.append(hit)
		return goodhits
	def qual_check_R(dotdata_qual_check):
		out1=[]
		out2=[]
		for x in dotdata_qual_check:
			out1.append(x[0])
			out2.append(x[1])
		print out1
		print out2
	def qual_check_R_2(dotdata_qual_check,txt_file):
		fo=open(txt_file+'.QC','w')
		for x in dotdata_qual_check:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
	def qual_check_R_3(dotdata_qual_check):
		fo=open('/home/xuefzhao/temp.txt','w')
		for x in range(len(dotdata_qual_check[0])):
			print >>fo, ' '.join([str(i) for i in [dotdata_qual_check[0][x],dotdata_qual_check[1][x]]])
		fo.close()
	def qual_check_repetitive_region(dotdata_qual_check):
		#qual_check_R_2(dotdata_qual_check,txt_file)  #not necessary for validator
		diagnal=0
		other=[[],[]]
		for x in dotdata_qual_check:
			if x[0]==x[1]:
				diagnal+=1 
			else:
				if x[0]>x[1]:
					other[0].append(x[0])
					other[1].append(x[1])
		if float(len(other[0]))/float(len(dotdata_qual_check))>0.1 and float(len(other[0]))/float(len(dotdata_qual_check))<0.5:
			other_cluster=X_means_cluster_reformat(other)
			range_cluster=cluster_range_decide(other_cluster)
			size_cluster=cluster_size_decide(range_cluster)
		else:
			size_cluster=[0]
		return [float(diagnal)/float(len(dotdata_qual_check)),size_cluster]
	def qual_predict_repetitive_region(dotdata_qual_check):
		#search for all potential blocks (in diagnal / anti-diagnal direction)
		diagnal=0
		other=[[],[]]
		for x in dotdata_qual_check:
			if x[0]==x[1]:
				diagnal+=1 
			else:
				if x[0]>x[1]:
					other[0].append(x[0])
					other[1].append(x[1])
		out2=cluster_dis_to_diagnal(other)
		out3=[]
		for x in out2:
			out3.append([])
			for y in x:
				temp=[i for i in cluster_simple_dis(y) if len(i[0])>dots_num_cff]
				out3[-1]+=temp
		out4=[cluster_range_decide(out3[0]),cluster_range_decide(out3[1])]
		out5=[cluster_size_decide(out4[0]),cluster_size_decide(out4[1])]
		out4b=[[out4[0][i] for i in range(len(out5[0])) if out5[0][i]>100],[out4[1][i] for i in range(len(out5[1])) if out5[1][i]>100]]
		return out4b				
	def ref_seq_readin(ref,chrom,start,end,reverse_flag):
		#reverse=='TRUE': return rev-comp-seq
		#else: return original seq
		fref=os.popen(r'''samtools faidx %s %s:%d-%d'''%(ref,chrom,int(start),int(end)))
		fref.readline().strip().split()
		seq=''
		while True:
				pref=fref.readline().strip().split()
				if not pref: break
				seq+=pref[0]
		fref.close()
		if not reverse_flag=='TRUE':
			return seq
		else:
			return reverse(complementary(seq))
	def read_hash_unify(all_reads):
		out=[[],[],[]]
		for x in range(len(all_reads[0])):
			if not all_reads[0][x] in out[0]:
				out[0].append(all_reads[0][x])
				out[1].append(all_reads[1][x])
				out[2].append(all_reads[2][x])
		return out
	def read_hash_minimize(all_reads):
		all_reads_unique=read_hash_unify(all_reads)
		read_hash=all_reads_unique[0]
		miss_hash=all_reads_unique[1]
		name_hash=name_hash_modify(all_reads_unique[2])							
		if len(read_hash)>30:
			new_read_hash=random.sample(range(len(read_hash)),30)
			read_hash2=[read_hash[i] for i in new_read_hash]
			miss_hash2=[miss_hash[i] for i in new_read_hash]
			name_hash2=[name_hash[i] for i in new_read_hash]
			read_hash=read_hash2
			miss_hash=miss_hash2
			name_hash=name_hash2
		return [read_hash,miss_hash,name_hash]
	def ref_hash_modi(ref_hash):
		out={}
		for x in ref_hash.keys():
				out[x]=ref_hash[x]
				out[x+'^']=reverse(complementary(ref_hash[x]))
		return out
	def remove_files_short(txt_file):
		for x in os.listdir('/'.join(txt_file.split('/')[:-1])):
			if txt_file.split('/')[-1].replace('.txt','') in x:
				if not x.split('.')[-1]=='png':
					if not x.split('.')[-1]=='rsquare':
						if not x==txt_file.split('/')[-1]:
							if not x.split('.')[-2]=='start':
								os.system(r'''rm %s'''%('/'.join(txt_file.split('/')[:-1])+'/'+x))
	def reverse(seq):
		return seq[::-1]
	def subkeys(key, nth_base, inversions):
		subkeys_info = []
		keylen = len(key)
		# speed tip from:
		# http://wiki.python.org/moin/PythonSpeed/PerformanceTips#String_Concatenation
		if nth_base == 1:
			subkeys_info = [key]
		elif nth_base != 0:
			for k in range(nth_base):
				substr_list = [key[j] for j in range(keylen) if (j % nth_base == k)]
				subkeys_info.append("".join(substr_list))
		else:
			# nth_base = 0 is a special case for third base mismatches
			# for every codon, only include the first 2 bases in the hash
			subkeys_info = ["".join([key[i] for i in range(len(key)) if i % 3 != 2])]
		if inversions:
			for i in range(len(subkeys_info)):
				subkeys_info.append("".join([invert_base[c] for c in reversed(subkeys_info[i])]))
		return subkeys_info
	def shift_diagnal_for_csv(dotdata_ref):
		out=data_re_format(dotdata_ref)
		dis_info=cluster_dis_to_diagnal(out)
		dis_off=decide_main_diagnal(dis_info)
		return dis_off
	def tranform_diagnal_to_horizonal(out):
	    #transformation: x2=x+y, y2=x-y
	    #out=read_in_dotplot_files(filein)
	    out2=[[],[]]
	    for x in range(len(out[0])):
	        out2[0].append(out[0][x]+out[1][x])
	        out2[1].append(out[0][x]-out[1][x])
	    return out2
	def tranform_diagnal_to_distance(out):
	    out2=[[],[]]
	    for x in range(len(out[0])):
	        out2[0].append(abs(out[0][x]-out[1][x]))
	        out2[1].append(x)
	    return out2
	def tranform_anti_diagnal_to_distance(out):
	    out2=[[],[]]
	    for x in range(len(out[0])):
	        out2[0].append(out[0][x]+out[1][x])
	        out2[1].append(x)
	    return out2
	def tranform_horizonal_to_diagnal(out):
	    out2=[[],[]]
	    for x in range(len(out[0])):
	        out2[0].append(int(float(out[0][x]+out[1][x])/2.0))
	        out2[1].append(int(float(out[0][x]-out[1][x])/2.0))
	    return out2
	def upper_string(string):
		return ''.join([i.upper() for i in string])
	def write_dotfile(dotdata_for_record,rec_name,txt_file,rec_start):
		fout='.'.join(txt_file.split('.')[:-1])+'.ref.'+rec_name+'.start.'+str(rec_start)
		fo=open(fout,'w')
		for x in dotdata_for_record[0]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt1.'+rec_name+'.start.'+str(rec_start)
		fo=open(fout,'w')
		for x in dotdata_for_record[1]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt2.'+rec_name+'.start.'+str(rec_start)
		fo=open(fout,'w')
		for x in dotdata_for_record[2]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
	def write_dotfile_left(dotdata_for_record,rec_name,txt_file):
		fout='.'.join(txt_file.split('.')[:-1])+'.ref.left.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[0]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt1.left.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[1]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt2.left.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[2]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
	def write_dotfile_right(dotdata_for_record,rec_name,txt_file):
		fout='.'.join(txt_file.split('.')[:-1])+'.ref.right.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[0]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt1.right.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[1]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
		fout='.'.join(txt_file.split('.')[:-1])+'.alt2.right.'+rec_name+'.start.'+str(0)
		fo=open(fout,'w')
		for x in dotdata_for_record[2]:
			print >>fo, ' '.join([str(i) for i in x])
		fo.close()
	def write_null_individual_stat(txt_file):
		fout='.'.join(txt_file.split('.')[:-1])+'.pacval'
		fo=open(fout,'w')
		print >>fo, ' '.join(['alt','ref'])
		fo.close()
	def write_pacval_individual_stat_simple_short(txt_file,rsquare_ref,rsquare_alt1,rsquare_alt2,SV_index):
		fo=open('.'.join(txt_file.split('.')[:-1])+'.pacval','w')
		print >>fo, ' '.join(['alt','ref'])
		PacVal_score_hash[SV_index]=0
		if len(rsquare_ref)>0:
			#"""pick min Dis score from two alleles"""
			rsquare_alt_min=[min([rsquare_alt1[x],rsquare_alt2[x]]) for x in range(len(rsquare_ref))]
			#"""if denominator=0, assign a small number"""
			for x in range(len(rsquare_ref)):
				if rsquare_alt_min[x]==0:
					if rsquare_ref[x]>0:
						rsquare_alt_min[x]=0.0001*rsquare_ref[x]
					else:
						rsquare_ref[x]=0.0001
						rsquare_alt_min[x]=0.0001
			#""" modify stat from Dis to Dis(PacBio Read| Orignal Ref)/Dis(PacBio Read| Altered Ref)-1"""
			rsquare_out_ref=[0 for i in rsquare_ref]
			rsquare_out_alt_min=[float(rsquare_ref[x])/float(rsquare_alt_min[x])-1 for x in range(len(rsquare_alt_min))]
			qual_score=0
			total_reads=0
			for x in range(len(rsquare_out_ref)):
				y=[rsquare_out_alt_min[x],rsquare_out_ref[x]]
				if y[0]>y[1]: 
					qual_score+=1
				total_reads+=1
				print >>fo, ' '.join([str(i) for i in y])
			if total_reads>0:
				PacVal_score_hash[SV_index]=float(qual_score)/float(total_reads)
		fo.close()
	def write_pacval_individual_stat_simple_long(txt_file,rsquare_ref1,rsquare_ref2,rsquare_alt,SV_index):
		fo=open('.'.join(txt_file.split('.')[:-1])+'.pacval','w')
		print >>fo, ' '.join(['alt','ref'])
		PacVal_score_hash[SV_index]=0
		if len(rsquare_ref1)>0:
			fo=open('.'.join(txt_file.split('.')[:-1])+'.pacval','w')
			#"""pick Max Counts score from two refs"""
			rsquare_ref_max=[max([rsquare_ref1[x],rsquare_ref2[x]]) for x in range(len(rsquare_ref1))]
			#"""if denominator=0, assign a small number"""
			for x in range(len(rsquare_alt)):
				if rsquare_ref_max[x]==0:
					if rsquare_alt[x]>0:
						rsquare_ref_max[x]=0.0001*rsquare_alt[x]
					else:
						rsquare_ref_max[x]=0.0001
						rsquare_alt[x]=0.0001
			#""" modify stat from Counts to -1+Counts(PacBio Read| Altered Ref)/Dis(PacBio Read| Orignal Ref)"""
			rsquare_out_ref=[0 for i in rsquare_ref_max]
			rsquare_out_alt=[-1+float(rsquare_alt[x])/float(rsquare_ref_max[x]) for x in range(len(rsquare_alt))]
			qual_score=0
			total_reads=0
			for x in range(len(rsquare_out_ref)):
				print >>fo, ' '.join([str(i) for i in [rsquare_out_alt[x],rsquare_out_ref[x]]])
				if rsquare_out_alt[x]>0:
					qual_score+=1
				total_reads+=1
			if total_reads>0:
				PacVal_score_hash[SV_index]=float(qual_score)/float(total_reads)
		fo.close()
	def X_means_cluster(data_list):
	    temp_result=[i for i in k_means_cluster(data_list) if not i==[[],[]]]
	    if temp_result==[data_list]:
	        return temp_result[0]
	    else:
	        out=[]
	        for i in temp_result:
	            out+=X_means_cluster(i)
	        return out
	def X_means_cluster_reformat(data_list):
		out=X_means_cluster(data_list)
		out2=[]
		for y in range(len(out)/2):
			out2.append([out[2*y],out[2*y+1]])
		return out2
	def DEL_alt_make(genotype):
		#eg of genotype:[0,0],[0,1],[1,1]
		if type(genotype[0])==type(1) and type(genotype[1])==type(1):
			if sum(genotype)==0:
				kb='a/a'
			elif sum(genotype)==1:
				kb='/a'
			elif sum(genotype)==2:
				kb='/'
			else:
				kb='error'
			return kb
		else:
			print 'wrong genotype!'
			return 'error'
	def INV_alt_make(genotype):
		#eg of genotype:[0,0],[0,1],[1,1]
		if type(genotype[0])==type(1) and type(genotype[1])==type(1):
			if sum(genotype)==0:
				kb='a/a'
			elif sum(genotype)==1:
				kb='a^/a'
			elif sum(genotype)==2:
				kb='a^/a^'
			else:
				kb='error'
			return kb
		else:
			print 'wrong genotype!'
			return 'error'
	def DUP_TAN_alt_make(genotype):
		#eg of genotype:[0,0],[0,1],[1,1]
		if type(genotype[0])==type(1) and type(genotype[1])==type(1):
			if sum(genotype)==0:
				kb='a/a'
			elif sum(genotype)==1:
				kb='aa/a'
			elif sum(genotype)==2:
				kb='aa/aa'
			else:
				kb='error'
			return kb
		else:
			print 'wrong genotype!'
			return 'error'
	def INS_alt_make(genotype):
		if type(genotype[0])==type(1) and type(genotype[1])==type(1):
			if sum(genotype)==0:
				kb='ac/ac'
			elif sum(genotype)==1:
				kb='abc/ac'
			elif sum(genotype)==2:
				kb='abc/abc'
			else:
				kb='error'
			return kb
		else:
			print 'wrong genotype!'
			return 'error'		
	def CNV_alt_make(gt_temp,pin):
		alt_candidates=['<CN1>']+pin[4].split(',')
		gt_temp=Genotype_caller(pin)
		gt_info=[alt_candidates[x] for x in gt_temp]
		copynumber_info=[int(i.replace('<CN','').replace('>','')) for i in gt_info]
		kb='/'.join([''.join(['a' for i in range(copynumber_info[0])]),''.join(['a' for i in range(copynumber_info[1])])])
		return kb
	if function_name=='svelter':
		def svelter_read_in(filein):
			global PacVal_score_hash
			PacVal_score_hash={}
			out={}
			fin=open(filein)
			pin=fin.readline().strip().split()
			rec=-1
			for line in fin:
				pin=line.strip().split()
				rec+=1
				if not pin[4] in out.keys():
					out[pin[4]]={}
				if not pin[5] in out[pin[4]].keys():
					out[pin[4]][pin[5]]=[]
				if not pin[3].split(':') in out[pin[4]][pin[5]]:
					out[pin[4]][pin[5]].append(pin[3].split(':')+[rec])
			fin.close()
			return out
		def main():
			Command_parametre_readin()
			case_hash=svelter_read_in(dict_opts['--sv-input'])
			for k1 in case_hash.keys():
				for k2 in case_hash[k1].keys():
					for k3 in case_hash[k1][k2]:
						current_info=[k1,k2]+k3
						global plt_figure_index
						plt_figure_index=k3[-1]+1
						if len(k3)==3:
							if int(k3[2])-int(k3[1])<5000: 
								calcu_eu_dis_simple_short(out_path,sample_name,[k1,k2]+k3[:-1],k3[-1])
							else: 
								calcu_eu_dis_simple_long(out_path,sample_name,[k1,k2]+k3[:-1],k3[-1])
						else:
							if int(k3[-2])-int(k3[1])<5000:
								calcu_eu_dis_complex_short(out_path,sample_name,[k1,k2]+k3[:-1],k3[-1])
	if function_name=='vcf':
		#for input files in vcf format, we require these information in the info column: 
		#SVTYPE='svtype',
		#END=number, indicating end of the event
		#or SVLEN='length',indicating length of the insertion; for ins only
		#for any CNV records, pls refer to the 1KGP format
		def genotype_decide(pin,sample_pos):
			gt=pin[sample_pos]
			if '/' in gt:
				gt_new=gt.split('/')
			elif '|' in gt:
				gt_new=gt.split('|')
			else:
				gt_new=[0,0]
			gt_new=[int(i) for i in gt_new]
			return gt_new
		def SVtype_decide(pin):
			sv_type=''
			for x in pin[7].split(';'):
				if x.split('=')[0]=='SVTYPE':
					sv_type=x.split('=')[1]
			return sv_type
		def SVend_decide(pin):
			end=int(pin[1])
			for x in pin[7].split(';'):
				if x.split('=')[0]=='END':
					end=int(x.split('=')[1])
			if end>int(pin[1]):
				return end
			else:
				print 'error: SVend < SVstart'
		def SVlength_decide(pin):
			length=0
			for x in pin[7].split(';'):
				if x.split('=')[0]=='SVLEN':
					length=int(x.split('=')[1])
			if length>0:
				return length
			else: 
				print 'error: SVlength = 0'
		def Genotype_caller(pin):
			gt_pos=pin[8].split(':').index('GT')
			gt_out=pin[9].split(':')[gt_pos]
			if '/' in gt_out:
				if gt_out.split('/')[0] in ['0','1'] and gt_out.split('/')[1] in ['0','1']:
					return sorted([int(i) for i in gt_out.split('/')])
				else:
					#if GT look like './.', no idea how to interprete for now.
					return [0,0]
			elif '|' in gt_out:
				if gt_out.split('|')[0] in ['0','1'] and gt_out.split('|')[1] in ['0','1']:
					return sorted([int(i) for i in gt_out.split('|')])
				else:
					#if GT look like './.', no idea how to interprete for now.
					return [0,0]
		def SV_end_read(pin):
			end=0
			for x in pin[7].split(';'):
				if x.split('=')[0]=='END':
					end=int(x.split('=')[1])
			return end
		def SVtype_decide(pin):
			sv_type=''
			for x in pin[7].split(';'):
				if x.split('=')[0]=='SVTYPE':
					sv_type=x.split('=')[1]
			return sv_type
		def vcf_read_in(filein):
			global PacVal_score_hash
			PacVal_score_hash={}
			global PacVal_file_in
			PacVal_file_in=dict_opts['--sv-input']
			global PacVal_file_out
			PacVal_file_out=PacVal_file_in+'.PacVal'
			out=[]
			fin=open(filein)
			rec=-1
			for line in fin:
				pin=line.strip().split()
				if not pin[0][0]=='#': 
					rec+=1
					SVtype=SVtype_decide(pin)
					if SVtype=='DEL' or 'DEL' in pin[4]: 
						gt_temp=Genotype_caller(pin)
						ka='a/a'
						kb=DEL_alt_make(gt_temp)
						#if ka==kb: continue
						sv_start=int(pin[1])
						sv_end=SV_end_read(pin)
						if sv_end>sv_start:
							out.append([pin[0],sv_start,sv_end,ka,kb,rec])					
					elif SVtype=='INV':
						gt_temp=Genotype_caller(pin)
						ka='a/a'
						kb=INV_alt_make(gt_temp)
						#if ka==kb: continue
						sv_start=int(pin[1])
						sv_end=SV_end_read(pin)
						if sv_end>sv_start:
							out.append([pin[0],sv_start,sv_end,ka,kb,rec])
					elif SVtype=='DUP' or 'DUP' in pin[4]:
						gt_temp=Genotype_caller(pin)
						ka='a/a'
						kb=DUP_TAN_alt_make(gt_temp)
						#if ka==kb: continue
						sv_start=int(pin[1])
						sv_end=SV_end_read(pin)
						if sv_end>sv_start:
							out.append([pin[0],sv_start,sv_end,ka,kb,rec])
					elif 'INS' in SVtype or 'INS' in pin[4]:
						ka='ac/ac'
						gt_temp=Genotype_caller(pin)
						kb=INS_alt_make(gt_temp)
						sv_start=int(pin[1])
						SV_length=SVlength_decide(pin)
						out.append([pin[0],sv_start,SV_length,ka,kb,rec])
					elif SVtype=='CNV':
						gt_temp=Genotype_caller(pin)
						ka='a/a'
						kb=CNV_alt_make(gt_temp,pin)
						#if ka==kb: continue
						sv_start=int(pin[1])
						sv_end=SV_end_read(pin)
						if sv_end>sv_start:
							out.append([pin[0],sv_start,sv_end,ka,kb,rec])
					elif '[' in pin[4] or ']' in pin[4]:
						if ']' in pin[4] and pin[4].split(']')[0]=='':
							#eg:']13:123456]AGTNNNNNCAT'
							info=[pin[0],pin[1],pin[4].split(']')[1].split(':')[0],
									int(pin[4].split(']')[1].split(':')[1])-flank_length,
									int(pin[4].split(']')[1].split(':')[1]),
									pin[4].split(']')[2][:-1],
									pin[0],int(pin[1]),int(pin[1])+flank_length,'.','.']
							out.append(info+[rec])
						elif '[' in pin[4] and pin[4].split('[')[2]=='':
							#eg:'CAGTNNNNNCA[2:321682['
							info=[pin[0],pin[1],pin[0],int(pin[1])-flank_length,int(pin[1]),
									pin[4].split('[')[0][1:],
									pin[4].split('[')[1].split(':')[0],
									int(pin[4].split('[')[1].split(':')[1]),
									int(pin[4].split('[')[1].split(':')[1])+flank_length,'.','.']
							out.append(info+[rec])
						elif ']' in pin[4] and pin[4].split(']')[2]=='':
							info=[pin[0],pin[1],pin[0],int(pin[1])-flank_length,int(pin[1]),
									pin[4].split(']')[0][1:],
									pin[4].split(']')[1].split(':')[0],
									int(pin[4].split(']')[1].split(':')[1])-flank_length,
									int(pin[4].split(']')[1].split(':')[1]),'.','^']
							out.append(info+[rec])
						elif '[' in pin[4] and pin[4].split('[')[0]=='':
							info=[pin[0],pin[1],pin[4].split('[')[1].split(':')[0],
									int(pin[4].split('[')[1].split(':')[1]),
									int(pin[4].split('[')[1].split(':')[1])+flank_length,
									pin[4].split('[')[2][:-1],
									pin[0],int(pin[1]),int(pin[1])+flank_length,'^','.']
							out.append(info+[rec])
						else:
							print 'unconsidered situation'
							print pin
					elif pin[4]=='<INS>':continue
					elif pin[4]=='<CNV>':continue #for now. modify later
					elif pin[4]=='<DUP>':continue #for now. modify later
					elif pin[4]=='<INS:ME>':continue #for now. modify later
					#else:
					#SV_type=SVtype_decide(pin)
					else:
							print 'unconsidered situation'
							print pin
			fin.close()
			return out
		def chop_pacbio_read_left_vcf(bps,flank_length):
			#chop reads going from bps[1]-flank_length 
			bps_new=[bps[0],bps[2],bps[2]+flank_length]
			bam_in_new=bam_in_decide(bam_in,bps)
			if bam_in_new=='': return [[],[],[]]
			fbam=os.popen(r'''samtools view %s %s:%d-%d'''%(bam_in_new,bps_new[0],int(bps_new[1])-flank_length,int(bps_new[1])+flank_length))
			out=[]
			out2=[]
			out3=[]
			for line in fbam:
				pbam=line.strip().split()
				if not pbam[0]=='@': 
					if int(pbam[3])<int(bps_new[1])-flank_length+1:
						align_info=cigar2alignstart_left(pbam[5],int(pbam[3]),bps_new)
						align_start=align_info[0]
						miss_bp=align_info[1]+1
						if align_start<flank_length/2:
						#print [align_start,miss_bp]
							target_read=pbam[9][align_start:]
							if len(target_read)>2*flank_length:
								out.append(target_read[:2*flank_length])
								out2.append(miss_bp)
								out3.append(pbam[0])
			fbam.close()
			return [out,out2,out3]
		def calcu_eu_dis_csv_long_vcf(k1,SV_index):
			#eg of k1:['22', '50934615', '22', 50567289, 50567789, '', '22', 50934615, 50935115, '.', '.']
			case_name=str(SV_index)
			txt_file=out_path+case_name+'.txt'
			all_reads_left=chop_pacbio_read_left_vcf(k1[2:5],flank_length)
			read_hash_left=all_reads_left[0]
			miss_hash_left=all_reads_left[1]
			name_hash_left=name_hash_modify(all_reads_left[2])
			read_hash_right=[]
			seqs=Pacbio_prodce_ref_alt_multi_chrom(ref,flank_length,k1)
			seq2=seqs[0]
			seq2_QC=seqs[3]
			dotdata_qual_check=dotdata(window_size,seq2_QC,seq2_QC)
			region_QC_a=qual_check_repetitive_region(dotdata_qual_check)
			seq3=seqs[1]
			seq3_QC=seqs[4]
			dotdata_qual_check=dotdata(window_size,seq3_QC,seq3_QC)
			region_QC_b=qual_check_repetitive_region(dotdata_qual_check)
			if region_QC_a[0]>region_QC_Cff or sum(region_QC_a[1])/float(len(seq2))<0.3 or region_QC_b[0]>region_QC_Cff or sum(region_QC_b[1])/float(len(seq3))<0.3:
					seq4=seqs[2]
					rsquare_ref1=[]
					rsquare_ref2=[]
					rsquare_alt=[]
					if not read_hash_left==[]:
						new_read_hash_left=read_hash_minimize(all_reads_left)
						read_hash_left=new_read_hash_left[0]
						miss_hash_left=new_read_hash_left[1]
						name_hash_left=new_read_hash_left[2]
						miss_rec=-1
						rec_len=0
						for x in read_hash_left:
							miss_rec+=1
							y=x
							y2=miss_hash_left[miss_rec]
							y3=name_hash_left[miss_rec]
							dotdata_ref1=dotdata(window_size,y,seq2[y2:])
							dotdata_ref2=dotdata(window_size,y,seq3[y2:])
							dotdata_alt=dotdata(window_size,y,seq4[y2:])							
							rsquare_ref1.append(eu_dis_calcu_simple_long(dotdata_ref1))
							rsquare_ref2.append(eu_dis_calcu_simple_long(dotdata_ref2))
							rsquare_alt.append(eu_dis_calcu_simple_long(dotdata_alt))
							if not rsquare_alt==[]:
								if rsquare_alt[-1]-max([rsquare_ref1[-1],rsquare_ref2[-1]])>rec_len:
									rec_len=rsquare_alt[-1]-max([rsquare_ref1[-1],rsquare_ref2[-1]])
									rec_name=name_hash_left[miss_rec]
									rec_start=miss_hash_left[miss_rec]
									dotdata_for_record=[dotdata_ref1,dotdata_ref2,dotdata_alt]
									seq1=y
						if rec_len>0:
							if len(dotdata_for_record[0])>0:
								dotplot_subfigure_simple_long(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+rec_name+'.png')
					if not read_hash_right==[]:
						miss_rec=-1
						rec_len=0
						if len(read_hash_right)>20:
							read_num_sample=random.sample(range(len(read_hash_right)),20)
							new_read_hash_right=[read_hash_right[i] for i in read_num_sample]
							new_miss_hash_right=[miss_hash_right[i] for i in read_num_sample]
							new_name_hash_right=[name_hash_right[i] for i in read_num_sample]
							read_hash_right=new_read_hash_right
							miss_hash_right=new_miss_hash_right
							name_hash_right=new_name_hash_right
						for x in read_hash_right:
							miss_rec+=1
							y=x
							y3=name_hash_right[miss_rec]
							dotdata_ref1=dotdata(window_size,y,seq2[::-1])
							dotdata_ref2=dotdata(window_size,y,seq3[::-1])
							dotdata_alt=dotdata(window_size,y,seq4[::-1])							
							temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref1)
							if not temp_rsquare==0:
								rsquare_ref1.append(temp_rsquare)
							temp_rsquare=eu_dis_calcu_simple_long(dotdata_ref2)
							if not temp_rsquare==0:
								rsquare_ref2.append(temp_rsquare)
							temp_rsquare=eu_dis_calcu_simple_long(dotdata_alt)
							if not temp_rsquare==0:
								rsquare_alt.append(temp_rsquare)
							if not len(rsquare_ref1)==len(rsquare_ref2)==len(rsquare_alt):
								min_len=min([len(rsquare_ref1),len(rsquare_ref2),len(rsquare_alt)])
								rsquare_ref1=rsquare_ref1[:min_len]
								rsquare_ref2=rsquare_ref2[:min_len]
								rsquare_alt=rsquare_alt[:min_len]
							if not rsquare_ref2==[]:
								if max([rsquare_ref2[-1],rsquare_alt[-1]])-rsquare_ref1[-1]>rec_len:
									rec_len=max([rsquare_ref2[-1],rsquare_alt[-1]])-rsquare_ref1[-1]
									rec_name=y3
									rec_start=miss_hash_right[miss_rec]
									dotdata_for_record=[dotdata_ref1,dotdata_ref2,dotdata_alt]
						if rec_len>0:
							if not len(dotdata_for_record[0])>0:
								dotplot_subfigure_simple_long(window_size,seq1,seq2[rec_start:],seq3[rec_start:],seq4[rec_start:],out_path+sample_name+'.'+case_name+rec_name+'.png')
					write_pacval_individual_stat_simple_long(txt_file,rsquare_ref1,rsquare_ref2,rsquare_alt,SV_index)
					remove_files_short(txt_file)
			else:
				fo=open(out_file_Cannot_Validate,'a')
				print k1
				print >>fo, ' '.join([str(i) for i in k1])
				fo.close()
		def write_PacVal_score_hash():
			fo=open(PacVal_file_out,'w')
			rec=-1
			fin=open(PacVal_file_in)
			for line in fin:
				pin=line.strip().split()
				if not pin[0][0]=='#': 
					rec+=1
					if rec in PacVal_score_hash.keys():
						pin2=pin+[str(PacVal_score_hash[rec])]
					else:
						pin2=pin+['-1'] #SV locates in repetitive regions, cannot validate
					print >>fo, ' '.join([str(i) for i in pin2])
			fin.close()
			fo.close()
		def Insertion_ref_recognize(ref_letter):
			#return 0 if ref letter, 1 else
			#eg of ref_letter: abc/abc ,  ac/ac
			#eg of normal ref: abc/abc
			#eg of abnormal ref: ac/ab
			out=1
			if ref_letter.split('/')[0]==ref_letter.split('/')[1]:
				test_a=[ord(x) for x in ref_letter.split('/')[0]]
				test_b=[test_a[x+1]-test_a[x] for x in range(len(test_a)-1)]
				test_c=[i for i in test_b if i>1]
				if test_c==[]:
					out=0
			return out
		def case_hash_unify(case_hash):
			out=[]
			rec=[]
			for x in case_hash:
				if not '.' in x and not '^' in x:
					if not x in out:
						out.append(x)
				else:
					if not x[2:-1] in rec:
						rec.append(x[2:-1])
						out.append(x)
			return out 
		def main():
			Command_parametre_readin()
			case_hash=vcf_read_in(dict_opts['--sv-input'])
			case_hash_unique=case_hash_unify(case_hash)
			for k1 in case_hash_unique:
				print k1
				global plt_figure_index
				plt_figure_index=k1[-1]+1
				if not '.' in k1 and not '^' in k1:
					if not k1[3]==k1[4]:
						if Insertion_ref_recognize(k1[3])==0:
							if k1[2]-k1[1]<5000:
								calcu_eu_dis_simple_short(out_path,sample_name,k1[3:5]+k1[:3],k1[-1])
							else: 
								calcu_eu_dis_simple_long(out_path,sample_name,k1[3:5]+k1[:3],k1[-1])
						else: #insertion
							if k1[2]<5000:
								calcu_eu_dis_simple_ins_short(out_path,sample_name,k1[3:5]+k1[:3],k1[-1])
							else:
								print k1
				else:
					if k1[-2]=='.': #we only consider reads going through first junc in forward direction for now. would conside the other part later, when I found a better solution/might need secondary alignment
						calcu_eu_dis_csv_long_vcf(k1[:-1],k1[-1])
			write_PacVal_score_hash()
	if function_name=='bed':
		def write_PacVal_score_hash():
			fo=open(PacVal_file_out,'w')
			rec=-1
			fin=open(PacVal_file_in)
			for line in fin:
				pin=line.strip().split()
				rec+=1
				if rec in PacVal_score_hash.keys():
					pin2=pin+[str(PacVal_score_hash[rec])]
				else:
					pin2=pin+['-1'] #SV locates in repetitive regions, cannot validate
				print >>fo, ' '.join([str(i) for i in pin2])
			fin.close()
			fo.close()
		def bed_readin(dict_opts):
			global PacVal_file_in
			PacVal_file_in=dict_opts['--sv-input']
			filein=dict_opts['--sv-input']
			global PacVal_file_out
			PacVal_file_out=filein+'.PacVal'
			global PacVal_score_hash
			PacVal_score_hash={}
			sv_type=dict_opts['--sv-type']
			ka='a/a'
			if sv_type in ['DEL','del','deletion','DELETION']:
				kb=DEL_alt_make([1,1])
			elif sv_type in ['INV','inv','inversion','INVERSION']:
				kb=INV_alt_make([1,1])
			elif sv_type in ['DUP_TANDEM']:
				kb=DUP_TAN_alt_make([1,1])
			else:
				print 'error: sv type not recognized!'
				kb='a/a'
				return 'Error'
			out_hash={}
			fin=open(filein)
			rec=-1
			for line in fin:
				rec+=1
				pin=line.strip().split()
				if not pin[0] in out_hash.keys():
					out_hash[pin[0]]=[]
				kb_new=kb
				if len(pin)>3:
					if pin[3] in ['het','HET','heter','heterozygous']:
						kb_new='/'.join([kb.split('/')[0],ka.split('/')[0]])
					else:
						kb_new=kb
				pin_info=[pin[0]]+[int(i) for i in pin[1:3]]+[ka,kb_new,rec]
				if not pin_info in out_hash[pin[0]]:
					out_hash[pin[0]].append(pin_info)
			fin.close()
			return out_hash
		def main():
			Command_parametre_readin()
			case_hash=bed_readin(dict_opts)
			global plt_figure_index
			plt_figure_index=0
			for k2 in sorted(case_hash.keys()):
				for k1 in case_hash[k2]:
					print k1
					plt_figure_index+=1
					if not '.' in k1 and not '^' in k1:
						if k1[2]-k1[1]<5000:
							calcu_eu_dis_simple_short(out_path,sample_name,k1[3:5]+k1[:3],k1[-1])
						else: 
							calcu_eu_dis_simple_long(out_path,sample_name,k1[3:5]+k1[:3],k1[-1])
			write_PacVal_score_hash()

time1=time.time()
main()
time2=time.time2()
print 'VaLoR Done!'
print 'Time Consuming:'+str(time2-time1)